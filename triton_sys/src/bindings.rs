/* automatically generated by rust-bindgen 0.64.0 */

pub const true_: u32 = 1;
pub const false_: u32 = 0;
pub const __bool_true_false_are_defined: u32 = 1;
pub const _STDINT_H: u32 = 1;
pub const _FEATURES_H: u32 = 1;
pub const _DEFAULT_SOURCE: u32 = 1;
pub const __GLIBC_USE_ISOC2X: u32 = 0;
pub const __USE_ISOC11: u32 = 1;
pub const __USE_ISOC99: u32 = 1;
pub const __USE_ISOC95: u32 = 1;
pub const __USE_POSIX_IMPLICITLY: u32 = 1;
pub const _POSIX_SOURCE: u32 = 1;
pub const _POSIX_C_SOURCE: u32 = 200809;
pub const __USE_POSIX: u32 = 1;
pub const __USE_POSIX2: u32 = 1;
pub const __USE_POSIX199309: u32 = 1;
pub const __USE_POSIX199506: u32 = 1;
pub const __USE_XOPEN2K: u32 = 1;
pub const __USE_XOPEN2K8: u32 = 1;
pub const _ATFILE_SOURCE: u32 = 1;
pub const __USE_MISC: u32 = 1;
pub const __USE_ATFILE: u32 = 1;
pub const __USE_FORTIFY_LEVEL: u32 = 0;
pub const __GLIBC_USE_DEPRECATED_GETS: u32 = 0;
pub const __GLIBC_USE_DEPRECATED_SCANF: u32 = 0;
pub const _STDC_PREDEF_H: u32 = 1;
pub const __STDC_IEC_559__: u32 = 1;
pub const __STDC_IEC_559_COMPLEX__: u32 = 1;
pub const __STDC_ISO_10646__: u32 = 201706;
pub const __GNU_LIBRARY__: u32 = 6;
pub const __GLIBC__: u32 = 2;
pub const __GLIBC_MINOR__: u32 = 31;
pub const _SYS_CDEFS_H: u32 = 1;
pub const __glibc_c99_flexarr_available: u32 = 1;
pub const __WORDSIZE: u32 = 64;
pub const __WORDSIZE_TIME64_COMPAT32: u32 = 1;
pub const __SYSCALL_WORDSIZE: u32 = 64;
pub const __LONG_DOUBLE_USES_FLOAT128: u32 = 0;
pub const __HAVE_GENERIC_SELECTION: u32 = 1;
pub const __GLIBC_USE_LIB_EXT2: u32 = 0;
pub const __GLIBC_USE_IEC_60559_BFP_EXT: u32 = 0;
pub const __GLIBC_USE_IEC_60559_BFP_EXT_C2X: u32 = 0;
pub const __GLIBC_USE_IEC_60559_FUNCS_EXT: u32 = 0;
pub const __GLIBC_USE_IEC_60559_FUNCS_EXT_C2X: u32 = 0;
pub const __GLIBC_USE_IEC_60559_TYPES_EXT: u32 = 0;
pub const _BITS_TYPES_H: u32 = 1;
pub const __TIMESIZE: u32 = 64;
pub const _BITS_TYPESIZES_H: u32 = 1;
pub const __OFF_T_MATCHES_OFF64_T: u32 = 1;
pub const __INO_T_MATCHES_INO64_T: u32 = 1;
pub const __RLIM_T_MATCHES_RLIM64_T: u32 = 1;
pub const __STATFS_MATCHES_STATFS64: u32 = 1;
pub const __FD_SETSIZE: u32 = 1024;
pub const _BITS_TIME64_H: u32 = 1;
pub const _BITS_WCHAR_H: u32 = 1;
pub const _BITS_STDINT_INTN_H: u32 = 1;
pub const _BITS_STDINT_UINTN_H: u32 = 1;
pub const INT8_MIN: i32 = -128;
pub const INT16_MIN: i32 = -32768;
pub const INT32_MIN: i32 = -2147483648;
pub const INT8_MAX: u32 = 127;
pub const INT16_MAX: u32 = 32767;
pub const INT32_MAX: u32 = 2147483647;
pub const UINT8_MAX: u32 = 255;
pub const UINT16_MAX: u32 = 65535;
pub const UINT32_MAX: u32 = 4294967295;
pub const INT_LEAST8_MIN: i32 = -128;
pub const INT_LEAST16_MIN: i32 = -32768;
pub const INT_LEAST32_MIN: i32 = -2147483648;
pub const INT_LEAST8_MAX: u32 = 127;
pub const INT_LEAST16_MAX: u32 = 32767;
pub const INT_LEAST32_MAX: u32 = 2147483647;
pub const UINT_LEAST8_MAX: u32 = 255;
pub const UINT_LEAST16_MAX: u32 = 65535;
pub const UINT_LEAST32_MAX: u32 = 4294967295;
pub const INT_FAST8_MIN: i32 = -128;
pub const INT_FAST16_MIN: i64 = -9223372036854775808;
pub const INT_FAST32_MIN: i64 = -9223372036854775808;
pub const INT_FAST8_MAX: u32 = 127;
pub const INT_FAST16_MAX: u64 = 9223372036854775807;
pub const INT_FAST32_MAX: u64 = 9223372036854775807;
pub const UINT_FAST8_MAX: u32 = 255;
pub const UINT_FAST16_MAX: i32 = -1;
pub const UINT_FAST32_MAX: i32 = -1;
pub const INTPTR_MIN: i64 = -9223372036854775808;
pub const INTPTR_MAX: u64 = 9223372036854775807;
pub const UINTPTR_MAX: i32 = -1;
pub const PTRDIFF_MIN: i64 = -9223372036854775808;
pub const PTRDIFF_MAX: u64 = 9223372036854775807;
pub const SIG_ATOMIC_MIN: i32 = -2147483648;
pub const SIG_ATOMIC_MAX: u32 = 2147483647;
pub const SIZE_MAX: i32 = -1;
pub const WINT_MIN: u32 = 0;
pub const WINT_MAX: u32 = 4294967295;
pub const TRITONSERVER_API_VERSION_MAJOR: u32 = 1;
pub const TRITONSERVER_API_VERSION_MINOR: u32 = 17;
pub type wchar_t = ::std::os::raw::c_int;
#[repr(C)]
#[repr(align(16))]
#[derive(Debug, Copy, Clone)]
pub struct max_align_t {
    pub __clang_max_align_nonce1: ::std::os::raw::c_longlong,
    pub __bindgen_padding_0: u64,
    pub __clang_max_align_nonce2: u128,
}
#[test]
fn bindgen_test_layout_max_align_t() {
    const UNINIT: ::std::mem::MaybeUninit<max_align_t> = ::std::mem::MaybeUninit::uninit();
    let ptr = UNINIT.as_ptr();
    assert_eq!(
        ::std::mem::size_of::<max_align_t>(),
        32usize,
        concat!("Size of: ", stringify!(max_align_t))
    );
    assert_eq!(
        ::std::mem::align_of::<max_align_t>(),
        16usize,
        concat!("Alignment of ", stringify!(max_align_t))
    );
    assert_eq!(
        unsafe { ::std::ptr::addr_of!((*ptr).__clang_max_align_nonce1) as usize - ptr as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(max_align_t),
            "::",
            stringify!(__clang_max_align_nonce1)
        )
    );
    assert_eq!(
        unsafe { ::std::ptr::addr_of!((*ptr).__clang_max_align_nonce2) as usize - ptr as usize },
        16usize,
        concat!(
            "Offset of field: ",
            stringify!(max_align_t),
            "::",
            stringify!(__clang_max_align_nonce2)
        )
    );
}
pub type __u_char = ::std::os::raw::c_uchar;
pub type __u_short = ::std::os::raw::c_ushort;
pub type __u_int = ::std::os::raw::c_uint;
pub type __u_long = ::std::os::raw::c_ulong;
pub type __int8_t = ::std::os::raw::c_schar;
pub type __uint8_t = ::std::os::raw::c_uchar;
pub type __int16_t = ::std::os::raw::c_short;
pub type __uint16_t = ::std::os::raw::c_ushort;
pub type __int32_t = ::std::os::raw::c_int;
pub type __uint32_t = ::std::os::raw::c_uint;
pub type __int64_t = ::std::os::raw::c_long;
pub type __uint64_t = ::std::os::raw::c_ulong;
pub type __int_least8_t = __int8_t;
pub type __uint_least8_t = __uint8_t;
pub type __int_least16_t = __int16_t;
pub type __uint_least16_t = __uint16_t;
pub type __int_least32_t = __int32_t;
pub type __uint_least32_t = __uint32_t;
pub type __int_least64_t = __int64_t;
pub type __uint_least64_t = __uint64_t;
pub type __quad_t = ::std::os::raw::c_long;
pub type __u_quad_t = ::std::os::raw::c_ulong;
pub type __intmax_t = ::std::os::raw::c_long;
pub type __uintmax_t = ::std::os::raw::c_ulong;
pub type __dev_t = ::std::os::raw::c_ulong;
pub type __uid_t = ::std::os::raw::c_uint;
pub type __gid_t = ::std::os::raw::c_uint;
pub type __ino_t = ::std::os::raw::c_ulong;
pub type __ino64_t = ::std::os::raw::c_ulong;
pub type __mode_t = ::std::os::raw::c_uint;
pub type __nlink_t = ::std::os::raw::c_ulong;
pub type __off_t = ::std::os::raw::c_long;
pub type __off64_t = ::std::os::raw::c_long;
pub type __pid_t = ::std::os::raw::c_int;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct __fsid_t {
    pub __val: [::std::os::raw::c_int; 2usize],
}
#[test]
fn bindgen_test_layout___fsid_t() {
    const UNINIT: ::std::mem::MaybeUninit<__fsid_t> = ::std::mem::MaybeUninit::uninit();
    let ptr = UNINIT.as_ptr();
    assert_eq!(
        ::std::mem::size_of::<__fsid_t>(),
        8usize,
        concat!("Size of: ", stringify!(__fsid_t))
    );
    assert_eq!(
        ::std::mem::align_of::<__fsid_t>(),
        4usize,
        concat!("Alignment of ", stringify!(__fsid_t))
    );
    assert_eq!(
        unsafe { ::std::ptr::addr_of!((*ptr).__val) as usize - ptr as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(__fsid_t),
            "::",
            stringify!(__val)
        )
    );
}
pub type __clock_t = ::std::os::raw::c_long;
pub type __rlim_t = ::std::os::raw::c_ulong;
pub type __rlim64_t = ::std::os::raw::c_ulong;
pub type __id_t = ::std::os::raw::c_uint;
pub type __time_t = ::std::os::raw::c_long;
pub type __useconds_t = ::std::os::raw::c_uint;
pub type __suseconds_t = ::std::os::raw::c_long;
pub type __daddr_t = ::std::os::raw::c_int;
pub type __key_t = ::std::os::raw::c_int;
pub type __clockid_t = ::std::os::raw::c_int;
pub type __timer_t = *mut ::std::os::raw::c_void;
pub type __blksize_t = ::std::os::raw::c_long;
pub type __blkcnt_t = ::std::os::raw::c_long;
pub type __blkcnt64_t = ::std::os::raw::c_long;
pub type __fsblkcnt_t = ::std::os::raw::c_ulong;
pub type __fsblkcnt64_t = ::std::os::raw::c_ulong;
pub type __fsfilcnt_t = ::std::os::raw::c_ulong;
pub type __fsfilcnt64_t = ::std::os::raw::c_ulong;
pub type __fsword_t = ::std::os::raw::c_long;
pub type __ssize_t = ::std::os::raw::c_long;
pub type __syscall_slong_t = ::std::os::raw::c_long;
pub type __syscall_ulong_t = ::std::os::raw::c_ulong;
pub type __loff_t = __off64_t;
pub type __caddr_t = *mut ::std::os::raw::c_char;
pub type __intptr_t = ::std::os::raw::c_long;
pub type __socklen_t = ::std::os::raw::c_uint;
pub type __sig_atomic_t = ::std::os::raw::c_int;
pub type int_least8_t = __int_least8_t;
pub type int_least16_t = __int_least16_t;
pub type int_least32_t = __int_least32_t;
pub type int_least64_t = __int_least64_t;
pub type uint_least8_t = __uint_least8_t;
pub type uint_least16_t = __uint_least16_t;
pub type uint_least32_t = __uint_least32_t;
pub type uint_least64_t = __uint_least64_t;
pub type int_fast8_t = ::std::os::raw::c_schar;
pub type int_fast16_t = ::std::os::raw::c_long;
pub type int_fast32_t = ::std::os::raw::c_long;
pub type int_fast64_t = ::std::os::raw::c_long;
pub type uint_fast8_t = ::std::os::raw::c_uchar;
pub type uint_fast16_t = ::std::os::raw::c_ulong;
pub type uint_fast32_t = ::std::os::raw::c_ulong;
pub type uint_fast64_t = ::std::os::raw::c_ulong;
pub type intmax_t = __intmax_t;
pub type uintmax_t = __uintmax_t;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONSERVER_BufferAttributes {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONSERVER_Error {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONSERVER_InferenceRequest {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONSERVER_InferenceResponse {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONSERVER_InferenceTrace {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONSERVER_Message {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONSERVER_Metrics {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONSERVER_Parameter {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONSERVER_ResponseAllocator {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONSERVER_Server {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONSERVER_ServerOptions {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONSERVER_Metric {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct TRITONSERVER_MetricFamily {
    _unused: [u8; 0],
}
extern "C" {
    #[doc = " Get the TRITONBACKEND API version supported by the Triton shared\n library. This value can be compared against the\n TRITONSERVER_API_VERSION_MAJOR and TRITONSERVER_API_VERSION_MINOR\n used to build the client to ensure that Triton shared library is\n compatible with the client.\n\n \\param major Returns the TRITONSERVER API major version supported\n by Triton.\n \\param minor Returns the TRITONSERVER API minor version supported\n by Triton.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ApiVersion(major: *mut u32, minor: *mut u32) -> *mut TRITONSERVER_Error;
}
pub const TRITONSERVER_datatype_enum_TRITONSERVER_TYPE_INVALID: TRITONSERVER_datatype_enum = 0;
pub const TRITONSERVER_datatype_enum_TRITONSERVER_TYPE_BOOL: TRITONSERVER_datatype_enum = 1;
pub const TRITONSERVER_datatype_enum_TRITONSERVER_TYPE_UINT8: TRITONSERVER_datatype_enum = 2;
pub const TRITONSERVER_datatype_enum_TRITONSERVER_TYPE_UINT16: TRITONSERVER_datatype_enum = 3;
pub const TRITONSERVER_datatype_enum_TRITONSERVER_TYPE_UINT32: TRITONSERVER_datatype_enum = 4;
pub const TRITONSERVER_datatype_enum_TRITONSERVER_TYPE_UINT64: TRITONSERVER_datatype_enum = 5;
pub const TRITONSERVER_datatype_enum_TRITONSERVER_TYPE_INT8: TRITONSERVER_datatype_enum = 6;
pub const TRITONSERVER_datatype_enum_TRITONSERVER_TYPE_INT16: TRITONSERVER_datatype_enum = 7;
pub const TRITONSERVER_datatype_enum_TRITONSERVER_TYPE_INT32: TRITONSERVER_datatype_enum = 8;
pub const TRITONSERVER_datatype_enum_TRITONSERVER_TYPE_INT64: TRITONSERVER_datatype_enum = 9;
pub const TRITONSERVER_datatype_enum_TRITONSERVER_TYPE_FP16: TRITONSERVER_datatype_enum = 10;
pub const TRITONSERVER_datatype_enum_TRITONSERVER_TYPE_FP32: TRITONSERVER_datatype_enum = 11;
pub const TRITONSERVER_datatype_enum_TRITONSERVER_TYPE_FP64: TRITONSERVER_datatype_enum = 12;
pub const TRITONSERVER_datatype_enum_TRITONSERVER_TYPE_BYTES: TRITONSERVER_datatype_enum = 13;
pub const TRITONSERVER_datatype_enum_TRITONSERVER_TYPE_BF16: TRITONSERVER_datatype_enum = 14;
#[doc = " TRITONSERVER_DataType\n\n Tensor data types recognized by TRITONSERVER.\n"]
pub type TRITONSERVER_datatype_enum = ::std::os::raw::c_uint;
#[doc = " TRITONSERVER_DataType\n\n Tensor data types recognized by TRITONSERVER.\n"]
pub use self::TRITONSERVER_datatype_enum as TRITONSERVER_DataType;
extern "C" {
    #[doc = " Get the string representation of a data type. The returned string\n is not owned by the caller and so should not be modified or freed.\n\n \\param datatype The data type.\n \\return The string representation of the data type."]
    pub fn TRITONSERVER_DataTypeString(
        datatype: TRITONSERVER_DataType,
    ) -> *const ::std::os::raw::c_char;
}
extern "C" {
    #[doc = " Get the Triton datatype corresponding to a string representation\n of a datatype.\n\n \\param dtype The datatype string representation.\n \\return The Triton data type or TRITONSERVER_TYPE_INVALID if the\n string does not represent a data type."]
    pub fn TRITONSERVER_StringToDataType(
        dtype: *const ::std::os::raw::c_char,
    ) -> TRITONSERVER_DataType;
}
extern "C" {
    #[doc = " Get the size of a Triton datatype in bytes. Zero is returned for\n TRITONSERVER_TYPE_BYTES because it have variable size. Zero is\n returned for TRITONSERVER_TYPE_INVALID.\n\n \\param dtype The datatype.\n \\return The size of the datatype."]
    pub fn TRITONSERVER_DataTypeByteSize(datatype: TRITONSERVER_DataType) -> u32;
}
pub const TRITONSERVER_memorytype_enum_TRITONSERVER_MEMORY_CPU: TRITONSERVER_memorytype_enum = 0;
pub const TRITONSERVER_memorytype_enum_TRITONSERVER_MEMORY_CPU_PINNED:
    TRITONSERVER_memorytype_enum = 1;
pub const TRITONSERVER_memorytype_enum_TRITONSERVER_MEMORY_GPU: TRITONSERVER_memorytype_enum = 2;
#[doc = " TRITONSERVER_MemoryType\n\n Types of memory recognized by TRITONSERVER.\n"]
pub type TRITONSERVER_memorytype_enum = ::std::os::raw::c_uint;
#[doc = " TRITONSERVER_MemoryType\n\n Types of memory recognized by TRITONSERVER.\n"]
pub use self::TRITONSERVER_memorytype_enum as TRITONSERVER_MemoryType;
extern "C" {
    #[doc = " Get the string representation of a memory type. The returned\n string is not owned by the caller and so should not be modified or\n freed.\n\n \\param memtype The memory type.\n \\return The string representation of the memory type."]
    pub fn TRITONSERVER_MemoryTypeString(
        memtype: TRITONSERVER_MemoryType,
    ) -> *const ::std::os::raw::c_char;
}
pub const TRITONSERVER_parametertype_enum_TRITONSERVER_PARAMETER_STRING:
    TRITONSERVER_parametertype_enum = 0;
pub const TRITONSERVER_parametertype_enum_TRITONSERVER_PARAMETER_INT:
    TRITONSERVER_parametertype_enum = 1;
pub const TRITONSERVER_parametertype_enum_TRITONSERVER_PARAMETER_BOOL:
    TRITONSERVER_parametertype_enum = 2;
pub const TRITONSERVER_parametertype_enum_TRITONSERVER_PARAMETER_BYTES:
    TRITONSERVER_parametertype_enum = 3;
#[doc = " TRITONSERVER_ParameterType\n\n Types of parameters recognized by TRITONSERVER.\n"]
pub type TRITONSERVER_parametertype_enum = ::std::os::raw::c_uint;
#[doc = " TRITONSERVER_ParameterType\n\n Types of parameters recognized by TRITONSERVER.\n"]
pub use self::TRITONSERVER_parametertype_enum as TRITONSERVER_ParameterType;
extern "C" {
    #[doc = " Get the string representation of a parameter type. The returned\n string is not owned by the caller and so should not be modified or\n freed.\n\n \\param paramtype The parameter type.\n \\return The string representation of the parameter type."]
    pub fn TRITONSERVER_ParameterTypeString(
        paramtype: TRITONSERVER_ParameterType,
    ) -> *const ::std::os::raw::c_char;
}
extern "C" {
    #[doc = " Create a new parameter object. The caller takes ownership of the\n TRITONSERVER_Parameter object and must call TRITONSERVER_ParameterDelete to\n release the object. The object will maintain its own copy of the 'value'\n\n \\param name The parameter name.\n \\param type The parameter type.\n \\param value The pointer to the value.\n \\return A new TRITONSERVER_Parameter object. 'nullptr' will be returned if\n 'type' is 'TRITONSERVER_PARAMETER_BYTES'. The caller should use\n TRITONSERVER_ParameterBytesNew to create parameter with bytes type."]
    pub fn TRITONSERVER_ParameterNew(
        name: *const ::std::os::raw::c_char,
        type_: TRITONSERVER_ParameterType,
        value: *const ::std::os::raw::c_void,
    ) -> *mut TRITONSERVER_Parameter;
}
extern "C" {
    #[doc = " Create a new parameter object with type TRITONSERVER_PARAMETER_BYTES.\n The caller takes ownership of the TRITONSERVER_Parameter object and must\n call TRITONSERVER_ParameterDelete to release the object. The object only\n maintains a shallow copy of the 'byte_ptr' so the data content must be\n valid until the parameter object is deleted.\n\n \\param name The parameter name.\n \\param byte_ptr The pointer to the data content.\n \\param size The size of the data content.\n \\return A new TRITONSERVER_Error object."]
    pub fn TRITONSERVER_ParameterBytesNew(
        name: *const ::std::os::raw::c_char,
        byte_ptr: *const ::std::os::raw::c_void,
        size: u64,
    ) -> *mut TRITONSERVER_Parameter;
}
extern "C" {
    #[doc = " Delete an parameter object.\n\n \\param parameter The parameter object."]
    pub fn TRITONSERVER_ParameterDelete(parameter: *mut TRITONSERVER_Parameter);
}
pub const TRITONSERVER_instancegroupkind_enum_TRITONSERVER_INSTANCEGROUPKIND_AUTO:
    TRITONSERVER_instancegroupkind_enum = 0;
pub const TRITONSERVER_instancegroupkind_enum_TRITONSERVER_INSTANCEGROUPKIND_CPU:
    TRITONSERVER_instancegroupkind_enum = 1;
pub const TRITONSERVER_instancegroupkind_enum_TRITONSERVER_INSTANCEGROUPKIND_GPU:
    TRITONSERVER_instancegroupkind_enum = 2;
pub const TRITONSERVER_instancegroupkind_enum_TRITONSERVER_INSTANCEGROUPKIND_MODEL:
    TRITONSERVER_instancegroupkind_enum = 3;
#[doc = " TRITONSERVER_InstanceGroupKind\n\n Kinds of instance groups recognized by TRITONSERVER.\n"]
pub type TRITONSERVER_instancegroupkind_enum = ::std::os::raw::c_uint;
#[doc = " TRITONSERVER_InstanceGroupKind\n\n Kinds of instance groups recognized by TRITONSERVER.\n"]
pub use self::TRITONSERVER_instancegroupkind_enum as TRITONSERVER_InstanceGroupKind;
extern "C" {
    #[doc = " Get the string representation of an instance-group kind. The\n returned string is not owned by the caller and so should not be\n modified or freed.\n\n \\param kind The instance-group kind.\n \\return The string representation of the kind."]
    pub fn TRITONSERVER_InstanceGroupKindString(
        kind: TRITONSERVER_InstanceGroupKind,
    ) -> *const ::std::os::raw::c_char;
}
pub const TRITONSERVER_loglevel_enum_TRITONSERVER_LOG_INFO: TRITONSERVER_loglevel_enum = 0;
pub const TRITONSERVER_loglevel_enum_TRITONSERVER_LOG_WARN: TRITONSERVER_loglevel_enum = 1;
pub const TRITONSERVER_loglevel_enum_TRITONSERVER_LOG_ERROR: TRITONSERVER_loglevel_enum = 2;
pub const TRITONSERVER_loglevel_enum_TRITONSERVER_LOG_VERBOSE: TRITONSERVER_loglevel_enum = 3;
#[doc = " TRITONSERVER_Logging\n\n Types/levels of logging.\n"]
pub type TRITONSERVER_loglevel_enum = ::std::os::raw::c_uint;
#[doc = " TRITONSERVER_Logging\n\n Types/levels of logging.\n"]
pub use self::TRITONSERVER_loglevel_enum as TRITONSERVER_LogLevel;
pub const TRITONSERVER_logformat_enum_TRITONSERVER_LOG_DEFAULT: TRITONSERVER_logformat_enum = 0;
pub const TRITONSERVER_logformat_enum_TRITONSERVER_LOG_ISO8601: TRITONSERVER_logformat_enum = 1;
#[doc = "\n Format of logging.\n\n TRITONSERVER_LOG_DEFAULT: the log severity (L) and timestamp will be\n logged as \"LMMDD hh:mm:ss.ssssss\".\n\n TRITONSERVER_LOG_ISO8601: the log format will be \"YYYY-MM-DDThh:mm:ssZ L\".\n"]
pub type TRITONSERVER_logformat_enum = ::std::os::raw::c_uint;
#[doc = "\n Format of logging.\n\n TRITONSERVER_LOG_DEFAULT: the log severity (L) and timestamp will be\n logged as \"LMMDD hh:mm:ss.ssssss\".\n\n TRITONSERVER_LOG_ISO8601: the log format will be \"YYYY-MM-DDThh:mm:ssZ L\".\n"]
pub use self::TRITONSERVER_logformat_enum as TRITONSERVER_LogFormat;
extern "C" {
    #[doc = " Is a log level enabled?\n\n \\param level The log level.\n \\return True if the log level is enabled, false if not enabled."]
    pub fn TRITONSERVER_LogIsEnabled(level: TRITONSERVER_LogLevel) -> bool;
}
extern "C" {
    #[doc = " Log a message at a given log level if that level is enabled.\n\n \\param level The log level.\n \\param filename The file name of the location of the log message.\n \\param line The line number of the log message.\n \\param msg The log message.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_LogMessage(
        level: TRITONSERVER_LogLevel,
        filename: *const ::std::os::raw::c_char,
        line: ::std::os::raw::c_int,
        msg: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
pub const TRITONSERVER_errorcode_enum_TRITONSERVER_ERROR_UNKNOWN: TRITONSERVER_errorcode_enum = 0;
pub const TRITONSERVER_errorcode_enum_TRITONSERVER_ERROR_INTERNAL: TRITONSERVER_errorcode_enum = 1;
pub const TRITONSERVER_errorcode_enum_TRITONSERVER_ERROR_NOT_FOUND: TRITONSERVER_errorcode_enum = 2;
pub const TRITONSERVER_errorcode_enum_TRITONSERVER_ERROR_INVALID_ARG: TRITONSERVER_errorcode_enum =
    3;
pub const TRITONSERVER_errorcode_enum_TRITONSERVER_ERROR_UNAVAILABLE: TRITONSERVER_errorcode_enum =
    4;
pub const TRITONSERVER_errorcode_enum_TRITONSERVER_ERROR_UNSUPPORTED: TRITONSERVER_errorcode_enum =
    5;
pub const TRITONSERVER_errorcode_enum_TRITONSERVER_ERROR_ALREADY_EXISTS:
    TRITONSERVER_errorcode_enum = 6;
#[doc = " The TRITONSERVER_Error error codes"]
pub type TRITONSERVER_errorcode_enum = ::std::os::raw::c_uint;
#[doc = " The TRITONSERVER_Error error codes"]
pub use self::TRITONSERVER_errorcode_enum as TRITONSERVER_Error_Code;
extern "C" {
    #[doc = " Create a new error object. The caller takes ownership of the\n TRITONSERVER_Error object and must call TRITONSERVER_ErrorDelete to\n release the object.\n\n \\param code The error code.\n \\param msg The error message.\n \\return A new TRITONSERVER_Error object."]
    pub fn TRITONSERVER_ErrorNew(
        code: TRITONSERVER_Error_Code,
        msg: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Delete an error object.\n\n \\param error The error object."]
    pub fn TRITONSERVER_ErrorDelete(error: *mut TRITONSERVER_Error);
}
extern "C" {
    #[doc = " Get the error code.\n\n \\param error The error object.\n \\return The error code."]
    pub fn TRITONSERVER_ErrorCode(error: *mut TRITONSERVER_Error) -> TRITONSERVER_Error_Code;
}
extern "C" {
    #[doc = " Get the string representation of an error code. The returned\n string is not owned by the caller and so should not be modified or\n freed. The lifetime of the returned string extends only as long as\n 'error' and must not be accessed once 'error' is deleted.\n\n \\param error The error object.\n \\return The string representation of the error code."]
    pub fn TRITONSERVER_ErrorCodeString(
        error: *mut TRITONSERVER_Error,
    ) -> *const ::std::os::raw::c_char;
}
extern "C" {
    #[doc = " Get the error message. The returned string is not owned by the\n caller and so should not be modified or freed. The lifetime of the\n returned string extends only as long as 'error' and must not be\n accessed once 'error' is deleted.\n\n \\param error The error object.\n \\return The error message."]
    pub fn TRITONSERVER_ErrorMessage(
        error: *mut TRITONSERVER_Error,
    ) -> *const ::std::os::raw::c_char;
}
#[doc = " Type for allocation function that allocates a buffer to hold an\n output tensor.\n\n \\param allocator The allocator that is provided in the call to\n TRITONSERVER_InferenceRequestSetResponseCallback.\n \\param tensor_name The name of the output tensor to allocate for.\n \\param byte_size The size of the buffer to allocate.\n \\param memory_type The type of memory that the caller prefers for\n the buffer allocation.\n \\param memory_type_id The ID of the memory that the caller prefers\n for the buffer allocation.\n \\param userp The user data pointer that is provided as\n 'response_allocator_userp' in the call to\n TRITONSERVER_InferenceRequestSetResponseCallback.\n \\param buffer Returns a pointer to the allocated memory.\n \\param buffer_userp Returns a user-specified value to associate\n with the buffer, or nullptr if no user-specified value should be\n associated with the buffer. This value will be provided in the\n call to TRITONSERVER_ResponseAllocatorReleaseFn_t when the buffer\n is released and will also be returned by\n TRITONSERVER_InferenceResponseOutput.\n \\param actual_memory_type Returns the type of memory where the\n allocation resides. May be different than the type of memory\n requested by 'memory_type'.\n \\param actual_memory_type_id Returns the ID of the memory where\n the allocation resides. May be different than the ID of the memory\n requested by 'memory_type_id'.\n \\return a TRITONSERVER_Error object if a failure occurs while\n attempting an allocation. If an error is returned all other return\n values will be ignored."]
pub type TRITONSERVER_ResponseAllocatorAllocFn_t = ::std::option::Option<
    unsafe extern "C" fn(
        allocator: *mut TRITONSERVER_ResponseAllocator,
        tensor_name: *const ::std::os::raw::c_char,
        byte_size: usize,
        memory_type: TRITONSERVER_MemoryType,
        memory_type_id: i64,
        userp: *mut ::std::os::raw::c_void,
        buffer: *mut *mut ::std::os::raw::c_void,
        buffer_userp: *mut *mut ::std::os::raw::c_void,
        actual_memory_type: *mut TRITONSERVER_MemoryType,
        actual_memory_type_id: *mut i64,
    ) -> *mut TRITONSERVER_Error,
>;
#[doc = " Type for allocation function that allocates a buffer to hold an\n output tensor with buffer attributes. The callback function must fill in the\n appropriate buffer attributes information related to this buffer. If set,\n this function is always called after TRITONSERVER_ResponseAllocatorAllocFn_t\n function.\n\n \\param allocator The allocator that is provided in the call to\n TRITONSERVER_InferenceRequestSetResponseCallback.\n \\param tensor_name The name of the output tensor to allocate for.\n \\param buffer_attributes The buffer attributes associated with the buffer.\n \\param userp The user data pointer that is provided as\n 'response_allocator_userp' in the call to\n TRITONSERVER_InferenceRequestSetResponseCallback.\n \\param buffer_userp Returns a user-specified value to associate\n with the buffer, or nullptr if no user-specified value should be\n associated with the buffer. This value will be provided in the\n call to TRITONSERVER_ResponseAllocatorReleaseFn_t when the buffer\n is released and will also be returned by\n TRITONSERVER_InferenceResponseOutput.\n \\return a TRITONSERVER_Error object if a failure occurs while\n attempting an allocation. If an error is returned all other return\n values will be ignored."]
pub type TRITONSERVER_ResponseAllocatorBufferAttributesFn_t = ::std::option::Option<
    unsafe extern "C" fn(
        allocator: *mut TRITONSERVER_ResponseAllocator,
        tensor_name: *const ::std::os::raw::c_char,
        buffer_attributes: *mut TRITONSERVER_BufferAttributes,
        userp: *mut ::std::os::raw::c_void,
        buffer_userp: *mut ::std::os::raw::c_void,
    ) -> *mut TRITONSERVER_Error,
>;
#[doc = " Type for function that is called to query the allocator's preferred memory\n type and memory type ID. As much as possible, the allocator should attempt\n to return the same memory_type and memory_type_id values that will be\n returned by the subsequent call to TRITONSERVER_ResponseAllocatorAllocFn_t.\n But the allocator is not required to do so.\n\n \\param allocator The allocator that is provided in the call to\n TRITONSERVER_InferenceRequestSetResponseCallback.\n \\param userp The user data pointer that is provided as\n 'response_allocator_userp' in the call to\n TRITONSERVER_InferenceRequestSetResponseCallback.\n \\param tensor_name The name of the output tensor. This is optional\n and it should be set to nullptr to indicate that the tensor name has\n not determined.\n \\param byte_size The expected size of the buffer. This is optional\n and it should be set to nullptr to indicate that the byte size has\n not determined.\n \\param memory_type Acts as both input and output. On input gives\n the memory type preferred by the caller. Returns memory type preferred\n by the allocator, taken account of the caller preferred type.\n \\param memory_type_id Acts as both input and output. On input gives\n the memory type ID preferred by the caller. Returns memory type ID preferred\n by the allocator, taken account of the caller preferred type ID.\n \\return a TRITONSERVER_Error object if a failure occurs."]
pub type TRITONSERVER_ResponseAllocatorQueryFn_t = ::std::option::Option<
    unsafe extern "C" fn(
        allocator: *mut TRITONSERVER_ResponseAllocator,
        userp: *mut ::std::os::raw::c_void,
        tensor_name: *const ::std::os::raw::c_char,
        byte_size: *mut usize,
        memory_type: *mut TRITONSERVER_MemoryType,
        memory_type_id: *mut i64,
    ) -> *mut TRITONSERVER_Error,
>;
#[doc = " Type for function that is called when the server no longer holds\n any reference to a buffer allocated by\n TRITONSERVER_ResponseAllocatorAllocFn_t. In practice this function\n is typically called when the response object associated with the\n buffer is deleted by TRITONSERVER_InferenceResponseDelete.\n\n \\param allocator The allocator that is provided in the call to\n TRITONSERVER_InferenceRequestSetResponseCallback.\n \\param buffer Pointer to the buffer to be freed.\n \\param buffer_userp The user-specified value associated\n with the buffer in TRITONSERVER_ResponseAllocatorAllocFn_t.\n \\param byte_size The size of the buffer.\n \\param memory_type The type of memory holding the buffer.\n \\param memory_type_id The ID of the memory holding the buffer.\n \\return a TRITONSERVER_Error object if a failure occurs while\n attempting the release. If an error is returned Triton will not\n attempt to release the buffer again."]
pub type TRITONSERVER_ResponseAllocatorReleaseFn_t = ::std::option::Option<
    unsafe extern "C" fn(
        allocator: *mut TRITONSERVER_ResponseAllocator,
        buffer: *mut ::std::os::raw::c_void,
        buffer_userp: *mut ::std::os::raw::c_void,
        byte_size: usize,
        memory_type: TRITONSERVER_MemoryType,
        memory_type_id: i64,
    ) -> *mut TRITONSERVER_Error,
>;
#[doc = " Type for function that is called to indicate that subsequent\n allocation requests will refer to a new response.\n\n \\param allocator The allocator that is provided in the call to\n TRITONSERVER_InferenceRequestSetResponseCallback.\n \\param userp The user data pointer that is provided as\n 'response_allocator_userp' in the call to\n TRITONSERVER_InferenceRequestSetResponseCallback.\n \\return a TRITONSERVER_Error object if a failure occurs."]
pub type TRITONSERVER_ResponseAllocatorStartFn_t = ::std::option::Option<
    unsafe extern "C" fn(
        allocator: *mut TRITONSERVER_ResponseAllocator,
        userp: *mut ::std::os::raw::c_void,
    ) -> *mut TRITONSERVER_Error,
>;
extern "C" {
    #[doc = " Create a new response allocator object.\n\n The response allocator object is used by Triton to allocate\n buffers to hold the output tensors in inference responses. Most\n models generate a single response for each inference request\n (TRITONSERVER_TXN_ONE_TO_ONE). For these models the order of\n callbacks will be:\n\n   TRITONSERVER_ServerInferAsync called\n    - start_fn : optional (and typically not required)\n    - alloc_fn : called once for each output tensor in response\n   TRITONSERVER_InferenceResponseDelete called\n    - release_fn: called once for each output tensor in response\n\n For models that generate multiple responses for each inference\n request (TRITONSERVER_TXN_DECOUPLED), the start_fn callback can be\n used to determine sets of alloc_fn callbacks that belong to the\n same response:\n\n   TRITONSERVER_ServerInferAsync called\n    - start_fn\n    - alloc_fn : called once for each output tensor in response\n    - start_fn\n    - alloc_fn : called once for each output tensor in response\n      ...\n   For each response, TRITONSERVER_InferenceResponseDelete called\n    - release_fn: called once for each output tensor in the response\n\n In all cases the start_fn, alloc_fn and release_fn callback\n functions must be thread-safe. Typically making these functions\n thread-safe does not require explicit locking. The recommended way\n to implement these functions is to have each inference request\n provide a 'response_allocator_userp' object that is unique to that\n request with TRITONSERVER_InferenceRequestSetResponseCallback. The\n callback functions then operate only on this unique state. Locking\n is required only when the callback function needs to access state\n that is shared across inference requests (for example, a common\n allocation pool).\n\n \\param allocator Returns the new response allocator object.\n \\param alloc_fn The function to call to allocate buffers for result\n tensors.\n \\param release_fn The function to call when the server no longer\n holds a reference to an allocated buffer.\n \\param start_fn The function to call to indicate that the\n subsequent 'alloc_fn' calls are for a new response. This callback\n is optional (use nullptr to indicate that it should not be\n invoked).\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ResponseAllocatorNew(
        allocator: *mut *mut TRITONSERVER_ResponseAllocator,
        alloc_fn: TRITONSERVER_ResponseAllocatorAllocFn_t,
        release_fn: TRITONSERVER_ResponseAllocatorReleaseFn_t,
        start_fn: TRITONSERVER_ResponseAllocatorStartFn_t,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the buffer attributes function for a response allocator object.\n The function will be called after alloc_fn to set the buffer attributes\n associated with the output buffer.\n\n The thread-safy requirement for buffer_attributes_fn is the same as other\n allocator callbacks.\n\n \\param allocator The response allocator object.\n \\param buffer_attributes_fn The function to call to get the buffer\n attributes information for an allocated buffer.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ResponseAllocatorSetBufferAttributesFunction(
        allocator: *mut TRITONSERVER_ResponseAllocator,
        buffer_attributes_fn: TRITONSERVER_ResponseAllocatorBufferAttributesFn_t,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the query function to a response allocator object. Usually the\n function will be called before alloc_fn to understand what is the\n allocator's preferred memory type and memory type ID at the current\n situation to make different execution decision.\n\n The thread-safy requirement for query_fn is the same as other allocator\n callbacks.\n\n \\param allocator The response allocator object.\n \\param query_fn The function to call to query allocator's preferred memory\n type and memory type ID.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ResponseAllocatorSetQueryFunction(
        allocator: *mut TRITONSERVER_ResponseAllocator,
        query_fn: TRITONSERVER_ResponseAllocatorQueryFn_t,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Delete a response allocator.\n\n \\param allocator The response allocator object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ResponseAllocatorDelete(
        allocator: *mut TRITONSERVER_ResponseAllocator,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Create a new message object from serialized JSON string.\n\n \\param message The message object.\n \\param base The base of the serialized JSON.\n \\param byte_size The size, in bytes, of the serialized message.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_MessageNewFromSerializedJson(
        message: *mut *mut TRITONSERVER_Message,
        base: *const ::std::os::raw::c_char,
        byte_size: usize,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Delete a message object.\n\n \\param message The message object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_MessageDelete(
        message: *mut TRITONSERVER_Message,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the base and size of the buffer containing the serialized\n message in JSON format. The buffer is owned by the\n TRITONSERVER_Message object and should not be modified or freed by\n the caller. The lifetime of the buffer extends only as long as\n 'message' and must not be accessed once 'message' is deleted.\n\n \\param message The message object.\n \\param base Returns the base of the serialized message.\n \\param byte_size Returns the size, in bytes, of the serialized\n message.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_MessageSerializeToJson(
        message: *mut TRITONSERVER_Message,
        base: *mut *const ::std::os::raw::c_char,
        byte_size: *mut usize,
    ) -> *mut TRITONSERVER_Error;
}
pub const tritonserver_metricformat_enum_TRITONSERVER_METRIC_PROMETHEUS:
    tritonserver_metricformat_enum = 0;
#[doc = " Metric format types"]
pub type tritonserver_metricformat_enum = ::std::os::raw::c_uint;
#[doc = " Metric format types"]
pub use self::tritonserver_metricformat_enum as TRITONSERVER_MetricFormat;
extern "C" {
    #[doc = " Delete a metrics object.\n\n \\param metrics The metrics object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_MetricsDelete(
        metrics: *mut TRITONSERVER_Metrics,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get a buffer containing the metrics in the specified format. For\n each format the buffer contains the following:\n\n   TRITONSERVER_METRIC_PROMETHEUS: 'base' points to a single multiline\n   string (char*) that gives a text representation of the metrics in\n   prometheus format. 'byte_size' returns the length of the string\n   in bytes.\n\n The buffer is owned by the 'metrics' object and should not be\n modified or freed by the caller. The lifetime of the buffer\n extends only as long as 'metrics' and must not be accessed once\n 'metrics' is deleted.\n\n \\param metrics The metrics object.\n \\param format The format to use for the returned metrics.\n \\param base Returns a pointer to the base of the formatted\n metrics, as described above.\n \\param byte_size Returns the size, in bytes, of the formatted\n metrics.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_MetricsFormatted(
        metrics: *mut TRITONSERVER_Metrics,
        format: TRITONSERVER_MetricFormat,
        base: *mut *const ::std::os::raw::c_char,
        byte_size: *mut usize,
    ) -> *mut TRITONSERVER_Error;
}
#[doc = " Tracing disabled. No trace activities are reported."]
pub const tritonserver_tracelevel_enum_TRITONSERVER_TRACE_LEVEL_DISABLED:
    tritonserver_tracelevel_enum = 0;
#[doc = " Deprecated. Use TRITONSERVER_TRACE_LEVEL_TIMESTAMPS."]
pub const tritonserver_tracelevel_enum_TRITONSERVER_TRACE_LEVEL_MIN: tritonserver_tracelevel_enum =
    1;
#[doc = " Deprecated. Use TRITONSERVER_TRACE_LEVEL_TIMESTAMPS."]
pub const tritonserver_tracelevel_enum_TRITONSERVER_TRACE_LEVEL_MAX: tritonserver_tracelevel_enum =
    2;
#[doc = " Record timestamps for the inference request."]
pub const tritonserver_tracelevel_enum_TRITONSERVER_TRACE_LEVEL_TIMESTAMPS:
    tritonserver_tracelevel_enum = 4;
#[doc = " Record input and output tensor values for the inference request."]
pub const tritonserver_tracelevel_enum_TRITONSERVER_TRACE_LEVEL_TENSORS:
    tritonserver_tracelevel_enum = 8;
#[doc = " Trace levels. The trace level controls the type of trace\n activities that are reported for an inference request.\n\n Trace level values are power-of-2 and can be combined to trace\n multiple types of activities. For example, use\n (TRITONSERVER_TRACE_LEVEL_TIMESTAMPS |\n TRITONSERVER_TRACE_LEVEL_TENSORS) to trace both timestamps and\n tensors for an inference request.\n\n TRITONSERVER_TRACE_LEVEL_MIN and TRITONSERVER_TRACE_LEVEL_MAX are\n deprecated and should not be used."]
pub type tritonserver_tracelevel_enum = ::std::os::raw::c_uint;
#[doc = " Trace levels. The trace level controls the type of trace\n activities that are reported for an inference request.\n\n Trace level values are power-of-2 and can be combined to trace\n multiple types of activities. For example, use\n (TRITONSERVER_TRACE_LEVEL_TIMESTAMPS |\n TRITONSERVER_TRACE_LEVEL_TENSORS) to trace both timestamps and\n tensors for an inference request.\n\n TRITONSERVER_TRACE_LEVEL_MIN and TRITONSERVER_TRACE_LEVEL_MAX are\n deprecated and should not be used."]
pub use self::tritonserver_tracelevel_enum as TRITONSERVER_InferenceTraceLevel;
extern "C" {
    #[doc = " Get the string representation of a trace level. The returned\n string is not owned by the caller and so should not be modified or\n freed.\n\n \\param level The trace level.\n \\return The string representation of the trace level."]
    pub fn TRITONSERVER_InferenceTraceLevelString(
        level: TRITONSERVER_InferenceTraceLevel,
    ) -> *const ::std::os::raw::c_char;
}
pub const tritonserver_traceactivity_enum_TRITONSERVER_TRACE_REQUEST_START:
    tritonserver_traceactivity_enum = 0;
pub const tritonserver_traceactivity_enum_TRITONSERVER_TRACE_QUEUE_START:
    tritonserver_traceactivity_enum = 1;
pub const tritonserver_traceactivity_enum_TRITONSERVER_TRACE_COMPUTE_START:
    tritonserver_traceactivity_enum = 2;
pub const tritonserver_traceactivity_enum_TRITONSERVER_TRACE_COMPUTE_INPUT_END:
    tritonserver_traceactivity_enum = 3;
pub const tritonserver_traceactivity_enum_TRITONSERVER_TRACE_COMPUTE_OUTPUT_START:
    tritonserver_traceactivity_enum = 4;
pub const tritonserver_traceactivity_enum_TRITONSERVER_TRACE_COMPUTE_END:
    tritonserver_traceactivity_enum = 5;
pub const tritonserver_traceactivity_enum_TRITONSERVER_TRACE_REQUEST_END:
    tritonserver_traceactivity_enum = 6;
pub const tritonserver_traceactivity_enum_TRITONSERVER_TRACE_TENSOR_QUEUE_INPUT:
    tritonserver_traceactivity_enum = 7;
pub const tritonserver_traceactivity_enum_TRITONSERVER_TRACE_TENSOR_BACKEND_INPUT:
    tritonserver_traceactivity_enum = 8;
pub const tritonserver_traceactivity_enum_TRITONSERVER_TRACE_TENSOR_BACKEND_OUTPUT:
    tritonserver_traceactivity_enum = 9;
#[doc = " Trace activities"]
pub type tritonserver_traceactivity_enum = ::std::os::raw::c_uint;
#[doc = " Trace activities"]
pub use self::tritonserver_traceactivity_enum as TRITONSERVER_InferenceTraceActivity;
extern "C" {
    #[doc = " Get the string representation of a trace activity. The returned\n string is not owned by the caller and so should not be modified or\n freed.\n\n \\param activity The trace activity.\n \\return The string representation of the trace activity."]
    pub fn TRITONSERVER_InferenceTraceActivityString(
        activity: TRITONSERVER_InferenceTraceActivity,
    ) -> *const ::std::os::raw::c_char;
}
#[doc = " Type for trace timeline activity callback function. This callback function\n is used to report activity occurring for a trace. This function\n does not take ownership of 'trace' and so any information needed\n from that object must be copied before returning. The 'userp' data\n is the same as what is supplied in the call to\n TRITONSERVER_InferenceTraceNew."]
pub type TRITONSERVER_InferenceTraceActivityFn_t = ::std::option::Option<
    unsafe extern "C" fn(
        trace: *mut TRITONSERVER_InferenceTrace,
        activity: TRITONSERVER_InferenceTraceActivity,
        timestamp_ns: u64,
        userp: *mut ::std::os::raw::c_void,
    ),
>;
#[doc = " Type for trace tensor activity callback function. This callback function\n is used to report tensor activity occurring for a trace. This function\n does not take ownership of 'trace' and so any information needed\n from that object must be copied before returning. The 'userp' data\n is the same as what is supplied in the call to\n TRITONSERVER_InferenceTraceTensorNew."]
pub type TRITONSERVER_InferenceTraceTensorActivityFn_t = ::std::option::Option<
    unsafe extern "C" fn(
        trace: *mut TRITONSERVER_InferenceTrace,
        activity: TRITONSERVER_InferenceTraceActivity,
        name: *const ::std::os::raw::c_char,
        datatype: TRITONSERVER_DataType,
        base: *const ::std::os::raw::c_void,
        byte_size: usize,
        shape: *const i64,
        dim_count: u64,
        memory_type: TRITONSERVER_MemoryType,
        memory_type_id: i64,
        userp: *mut ::std::os::raw::c_void,
    ),
>;
#[doc = " Type for trace release callback function. This callback function\n is called when all activity for the trace has completed. The\n callback function takes ownership of the\n TRITONSERVER_InferenceTrace object. The 'userp' data is the same\n as what is supplied in the call to TRITONSERVER_InferenceTraceNew."]
pub type TRITONSERVER_InferenceTraceReleaseFn_t = ::std::option::Option<
    unsafe extern "C" fn(
        trace: *mut TRITONSERVER_InferenceTrace,
        userp: *mut ::std::os::raw::c_void,
    ),
>;
extern "C" {
    #[doc = " Create a new inference trace object. The caller takes ownership of\n the TRITONSERVER_InferenceTrace object and must call\n TRITONSERVER_InferenceTraceDelete to release the object.\n\n The activity callback function will be called to report activity\n for 'trace' as well as for any child traces that are spawned by\n 'trace', and so the activity callback must check the trace object\n to determine specifically what activity is being reported.\n\n The release callback is called for both 'trace' and for any child\n traces spawned by 'trace'.\n\n \\param trace Returns the new inference trace object.\n \\param level The tracing level.\n \\param parent_id The parent trace id for this trace. A value of 0\n indicates that there is not parent trace.\n \\param activity_fn The callback function where activity for the\n trace is reported.\n \\param release_fn The callback function called when all activity\n is complete for the trace.\n \\param trace_userp User-provided pointer that is delivered to\n the activity and release callback functions.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceTraceNew(
        trace: *mut *mut TRITONSERVER_InferenceTrace,
        level: TRITONSERVER_InferenceTraceLevel,
        parent_id: u64,
        activity_fn: TRITONSERVER_InferenceTraceActivityFn_t,
        release_fn: TRITONSERVER_InferenceTraceReleaseFn_t,
        trace_userp: *mut ::std::os::raw::c_void,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Create a new inference trace object. The caller takes ownership of\n the TRITONSERVER_InferenceTrace object and must call\n TRITONSERVER_InferenceTraceDelete to release the object.\n\n The timeline and tensor activity callback function will be called to report\n activity for 'trace' as well as for any child traces that are spawned by\n 'trace', and so the activity callback must check the trace object\n to determine specifically what activity is being reported.\n\n The release callback is called for both 'trace' and for any child\n traces spawned by 'trace'.\n\n \\param trace Returns the new inference trace object.\n \\param level The tracing level.\n \\param parent_id The parent trace id for this trace. A value of 0\n indicates that there is not parent trace.\n \\param activity_fn The callback function where timeline activity for the\n trace is reported.\n \\param tensor_activity_fn The callback function where tensor activity for\n the trace is reported.\n \\param release_fn The callback function called when all activity\n is complete for the trace.\n \\param trace_userp User-provided pointer that is delivered to\n the activity and release callback functions.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceTraceTensorNew(
        trace: *mut *mut TRITONSERVER_InferenceTrace,
        level: TRITONSERVER_InferenceTraceLevel,
        parent_id: u64,
        activity_fn: TRITONSERVER_InferenceTraceActivityFn_t,
        tensor_activity_fn: TRITONSERVER_InferenceTraceTensorActivityFn_t,
        release_fn: TRITONSERVER_InferenceTraceReleaseFn_t,
        trace_userp: *mut ::std::os::raw::c_void,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Delete a trace object.\n\n \\param trace The trace object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceTraceDelete(
        trace: *mut TRITONSERVER_InferenceTrace,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the id associated with a trace. Every trace is assigned an id\n that is unique across all traces created for a Triton server.\n\n \\param trace The trace.\n \\param id Returns the id associated with the trace.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceTraceId(
        trace: *mut TRITONSERVER_InferenceTrace,
        id: *mut u64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the parent id associated with a trace. The parent id indicates\n a parent-child relationship between two traces. A parent id value\n of 0 indicates that there is no parent trace.\n\n \\param trace The trace.\n \\param id Returns the parent id associated with the trace.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceTraceParentId(
        trace: *mut TRITONSERVER_InferenceTrace,
        parent_id: *mut u64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the name of the model associated with a trace. The caller does\n not own the returned string and must not modify or delete it. The\n lifetime of the returned string extends only as long as 'trace'.\n\n \\param trace The trace.\n \\param model_name Returns the name of the model associated with\n the trace.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceTraceModelName(
        trace: *mut TRITONSERVER_InferenceTrace,
        model_name: *mut *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the version of the model associated with a trace.\n\n \\param trace The trace.\n \\param model_version Returns the version of the model associated\n with the trace.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceTraceModelVersion(
        trace: *mut TRITONSERVER_InferenceTrace,
        model_version: *mut i64,
    ) -> *mut TRITONSERVER_Error;
}
pub const tritonserver_requestflag_enum_TRITONSERVER_REQUEST_FLAG_SEQUENCE_START:
    tritonserver_requestflag_enum = 1;
pub const tritonserver_requestflag_enum_TRITONSERVER_REQUEST_FLAG_SEQUENCE_END:
    tritonserver_requestflag_enum = 2;
#[doc = " Inference request flags. The enum values must be power-of-2 values."]
pub type tritonserver_requestflag_enum = ::std::os::raw::c_uint;
#[doc = " Inference request flags. The enum values must be power-of-2 values."]
pub use self::tritonserver_requestflag_enum as TRITONSERVER_RequestFlag;
pub const tritonserver_requestreleaseflag_enum_TRITONSERVER_REQUEST_RELEASE_ALL:
    tritonserver_requestreleaseflag_enum = 1;
#[doc = " Inference request release flags. The enum values must be\n power-of-2 values."]
pub type tritonserver_requestreleaseflag_enum = ::std::os::raw::c_uint;
#[doc = " Inference request release flags. The enum values must be\n power-of-2 values."]
pub use self::tritonserver_requestreleaseflag_enum as TRITONSERVER_RequestReleaseFlag;
pub const tritonserver_responsecompleteflag_enum_TRITONSERVER_RESPONSE_COMPLETE_FINAL:
    tritonserver_responsecompleteflag_enum = 1;
#[doc = " Inference response complete flags. The enum values must be\n power-of-2 values."]
pub type tritonserver_responsecompleteflag_enum = ::std::os::raw::c_uint;
#[doc = " Inference response complete flags. The enum values must be\n power-of-2 values."]
pub use self::tritonserver_responsecompleteflag_enum as TRITONSERVER_ResponseCompleteFlag;
#[doc = " Type for inference request release callback function. The callback\n indicates what type of release is being performed on the request\n and for some of these the callback function takes ownership of the\n TRITONSERVER_InferenceRequest object. The 'userp' data is the data\n provided as 'request_release_userp' in the call to\n TRITONSERVER_InferenceRequestSetReleaseCallback.\n\n One or more flags will be specified when the callback is invoked,\n and the callback must take the following actions:\n\n   - TRITONSERVER_REQUEST_RELEASE_ALL: The entire inference request\n     is being released and ownership is passed to the callback\n     function. Triton will not longer access the 'request' object\n     itself nor any input tensor data associated with the\n     request. The callback should free or otherwise manage the\n     'request' object and all associated tensor data.\n\n Note that currently TRITONSERVER_REQUEST_RELEASE_ALL should always\n be set when the callback is invoked but in the future that may\n change, so the callback should explicitly check for the flag\n before taking ownership of the request object.\n"]
pub type TRITONSERVER_InferenceRequestReleaseFn_t = ::std::option::Option<
    unsafe extern "C" fn(
        request: *mut TRITONSERVER_InferenceRequest,
        flags: u32,
        userp: *mut ::std::os::raw::c_void,
    ),
>;
#[doc = " Type for callback function indicating that an inference response\n has completed. The callback function takes ownership of the\n TRITONSERVER_InferenceResponse object. The 'userp' data is the\n data provided as 'response_userp' in the call to\n TRITONSERVER_InferenceRequestSetResponseCallback.\n\n One or more flags may be specified when the callback is invoked:\n\n   - TRITONSERVER_RESPONSE_COMPLETE_FINAL: Indicates that no more\n     responses will be generated for a given request (more\n     specifically, that no more responses will be generated for the\n     inference request that set this callback and 'userp'). When\n     this flag is set 'response' may be a response object or may be\n     nullptr. If 'response' is not nullptr, then 'response' is the\n     last response that Triton will produce for the request. If\n     'response' is nullptr then Triton is indicating that no more\n     responses will be produced for the request."]
pub type TRITONSERVER_InferenceResponseCompleteFn_t = ::std::option::Option<
    unsafe extern "C" fn(
        response: *mut TRITONSERVER_InferenceResponse,
        flags: u32,
        userp: *mut ::std::os::raw::c_void,
    ),
>;
extern "C" {
    #[doc = " Create a new inference request object.\n\n \\param inference_request Returns the new request object.\n \\param server the inference server object.\n \\param model_name The name of the model to use for the request.\n \\param model_version The version of the model to use for the\n request. If -1 then the server will choose a version based on the\n model's policy.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestNew(
        inference_request: *mut *mut TRITONSERVER_InferenceRequest,
        server: *mut TRITONSERVER_Server,
        model_name: *const ::std::os::raw::c_char,
        model_version: i64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Delete an inference request object.\n\n \\param inference_request The request object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestDelete(
        inference_request: *mut TRITONSERVER_InferenceRequest,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the ID for a request. The returned ID is owned by\n 'inference_request' and must not be modified or freed by the\n caller.\n\n \\param inference_request The request object.\n \\param id Returns the ID.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestId(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        id: *mut *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the ID for a request.\n\n \\param inference_request The request object.\n \\param id The ID.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestSetId(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        id: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the flag(s) associated with a request. On return 'flags' holds\n a bitwise-or of all flag values, see TRITONSERVER_RequestFlag for\n available flags.\n\n \\param inference_request The request object.\n \\param flags Returns the flags.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestFlags(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        flags: *mut u32,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the flag(s) associated with a request. 'flags' should hold a\n bitwise-or of all flag values, see TRITONSERVER_RequestFlag for\n available flags.\n\n \\param inference_request The request object.\n \\param flags The flags.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestSetFlags(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        flags: u32,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the correlation ID of the inference request as an unsigned integer.\n Default is 0, which indicates that the request has no correlation ID.\n If the correlation id associated with the inference request is a string,\n this function will return a failure. The correlation ID is used\n to indicate two or more inference request are related to each other.\n How this relationship is handled by the inference server is determined by\n the model's scheduling policy.\n\n \\param inference_request The request object.\n \\param correlation_id Returns the correlation ID.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestCorrelationId(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        correlation_id: *mut u64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the correlation ID of the inference request as a string.\n Default is empty \"\", which indicates that the request has no correlation ID.\n If the correlation id associated with the inference request is an unsigned\n integer, then this function will return a failure. The correlation ID\n is used to indicate two or more inference request are related to each other.\n How this relationship is handled by the inference server is determined by\n the model's scheduling policy.\n\n \\param inference_request The request object.\n \\param correlation_id Returns the correlation ID.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestCorrelationIdString(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        correlation_id: *mut *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the correlation ID of the inference request to be an unsigned integer.\n Default is 0, which indicates that the request has no correlation ID.\n The correlation ID is used to indicate two or more inference request\n are related to each other. How this relationship is handled by the\n inference server is determined by the model's scheduling policy.\n\n \\param inference_request The request object.\n \\param correlation_id The correlation ID.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestSetCorrelationId(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        correlation_id: u64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the correlation ID of the inference request to be a string.\n The correlation ID is used to indicate two or more inference\n request are related to each other. How this relationship is\n handled by the inference server is determined by the model's\n scheduling policy.\n\n \\param inference_request The request object.\n \\param correlation_id The correlation ID.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestSetCorrelationIdString(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        correlation_id: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the priority for a request. The default is 0 indicating that\n the request does not specify a priority and so will use the\n model's default priority.\n\n \\param inference_request The request object.\n \\param priority Returns the priority level.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestPriority(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        priority: *mut u32,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the priority for a request. The default is 0 indicating that\n the request does not specify a priority and so will use the\n model's default priority.\n\n \\param inference_request The request object.\n \\param priority The priority level.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestSetPriority(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        priority: u32,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the timeout for a request, in microseconds. The default is 0\n which indicates that the request has no timeout.\n\n \\param inference_request The request object.\n \\param timeout_us Returns the timeout, in microseconds.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestTimeoutMicroseconds(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        timeout_us: *mut u64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the timeout for a request, in microseconds. The default is 0\n which indicates that the request has no timeout.\n\n \\param inference_request The request object.\n \\param timeout_us The timeout, in microseconds.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestSetTimeoutMicroseconds(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        timeout_us: u64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Add an input to a request.\n\n \\param inference_request The request object.\n \\param name The name of the input.\n \\param datatype The type of the input. Valid type names are BOOL,\n UINT8, UINT16, UINT32, UINT64, INT8, INT16, INT32, INT64, FP16,\n FP32, FP64, and BYTES.\n \\param shape The shape of the input.\n \\param dim_count The number of dimensions of 'shape'.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestAddInput(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        name: *const ::std::os::raw::c_char,
        datatype: TRITONSERVER_DataType,
        shape: *const i64,
        dim_count: u64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Add a raw input to a request. The name recognized by the model, data type\n and shape of the input will be deduced from model configuration.\n This function must be called at most once on request with no other input to\n ensure the deduction is accurate.\n\n \\param inference_request The request object.\n \\param name The name of the input. This name is only used as a reference\n of the raw input in other Tritonserver APIs. It doesn't assoicate with the\n name used in the model.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestAddRawInput(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        name: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Remove an input from a request.\n\n \\param inference_request The request object.\n \\param name The name of the input.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestRemoveInput(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        name: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Remove all inputs from a request.\n\n \\param inference_request The request object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestRemoveAllInputs(
        inference_request: *mut TRITONSERVER_InferenceRequest,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Assign a buffer of data to an input. The buffer will be appended\n to any existing buffers for that input. The 'inference_request'\n object takes ownership of the buffer and so the caller should not\n modify or free the buffer until that ownership is released by\n 'inference_request' being deleted or by the input being removed\n from 'inference_request'.\n\n \\param inference_request The request object.\n \\param name The name of the input.\n \\param base The base address of the input data.\n \\param byte_size The size, in bytes, of the input data.\n \\param memory_type The memory type of the input data.\n \\param memory_type_id The memory type id of the input data.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestAppendInputData(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        name: *const ::std::os::raw::c_char,
        base: *const ::std::os::raw::c_void,
        byte_size: usize,
        memory_type: TRITONSERVER_MemoryType,
        memory_type_id: i64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Assign a buffer of data to an input for execution on all model instances\n with the specified host policy. The buffer will be appended to any existing\n buffers for that input on all devices with this host policy. The\n 'inference_request' object takes ownership of the buffer and so the caller\n should not modify or free the buffer until that ownership is released by\n 'inference_request' being deleted or by the input being removed from\n 'inference_request'. If the execution is scheduled on a device that does not\n have a input buffer specified using this function, then the input buffer\n specified with TRITONSERVER_InferenceRequestAppendInputData will be used so\n a non-host policy specific version of data must be added using that API.\n \\param inference_request The request object.\n \\param name The name of the input.\n \\param base The base address of the input data.\n \\param byte_size The size, in bytes, of the input data.\n \\param memory_type The memory type of the input data.\n \\param memory_type_id The memory type id of the input data.\n \\param host_policy_name All model instances executing with this host_policy\n will use this input buffer for execution.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestAppendInputDataWithHostPolicy(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        name: *const ::std::os::raw::c_char,
        base: *const ::std::os::raw::c_void,
        byte_size: usize,
        memory_type: TRITONSERVER_MemoryType,
        memory_type_id: i64,
        host_policy_name: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Assign a buffer of data to an input. The buffer will be appended\n to any existing buffers for that input. The 'inference_request'\n object takes ownership of the buffer and so the caller should not\n modify or free the buffer until that ownership is released by\n 'inference_request' being deleted or by the input being removed\n from 'inference_request'.\n\n \\param inference_request The request object.\n \\param name The name of the input.\n \\param base The base address of the input data.\n \\param buffer_attributes The buffer attrubutes of the input.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestAppendInputDataWithBufferAttributes(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        name: *const ::std::os::raw::c_char,
        base: *const ::std::os::raw::c_void,
        buffer_attributes: *mut TRITONSERVER_BufferAttributes,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Clear all input data from an input, releasing ownership of the\n buffer(s) that were appended to the input with\n TRITONSERVER_InferenceRequestAppendInputData or\n TRITONSERVER_InferenceRequestAppendInputDataWithHostPolicy\n \\param inference_request The request object.\n \\param name The name of the input."]
    pub fn TRITONSERVER_InferenceRequestRemoveAllInputData(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        name: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Add an output request to an inference request.\n\n \\param inference_request The request object.\n \\param name The name of the output.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestAddRequestedOutput(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        name: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Remove an output request from an inference request.\n\n \\param inference_request The request object.\n \\param name The name of the output.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestRemoveRequestedOutput(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        name: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Remove all output requests from an inference request.\n\n \\param inference_request The request object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestRemoveAllRequestedOutputs(
        inference_request: *mut TRITONSERVER_InferenceRequest,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the release callback for an inference request. The release\n callback is called by Triton to return ownership of the request\n object.\n\n \\param inference_request The request object.\n \\param request_release_fn The function called to return ownership\n of the 'inference_request' object.\n \\param request_release_userp User-provided pointer that is\n delivered to the 'request_release_fn' callback.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestSetReleaseCallback(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        request_release_fn: TRITONSERVER_InferenceRequestReleaseFn_t,
        request_release_userp: *mut ::std::os::raw::c_void,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the allocator and response callback for an inference\n request. The allocator is used to allocate buffers for any output\n tensors included in responses that are produced for this\n request. The response callback is called to return response\n objects representing responses produced for this request.\n\n \\param inference_request The request object.\n \\param response_allocator The TRITONSERVER_ResponseAllocator to use\n to allocate buffers to hold inference results.\n \\param response_allocator_userp User-provided pointer that is\n delivered to the response allocator's start and allocation functions.\n \\param response_fn The function called to deliver an inference\n response for this request.\n \\param response_userp User-provided pointer that is delivered to\n the 'response_fn' callback.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceRequestSetResponseCallback(
        inference_request: *mut TRITONSERVER_InferenceRequest,
        response_allocator: *mut TRITONSERVER_ResponseAllocator,
        response_allocator_userp: *mut ::std::os::raw::c_void,
        response_fn: TRITONSERVER_InferenceResponseCompleteFn_t,
        response_userp: *mut ::std::os::raw::c_void,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Delete an inference response object.\n\n \\param inference_response The response object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceResponseDelete(
        inference_response: *mut TRITONSERVER_InferenceResponse,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Return the error status of an inference response. Return a\n TRITONSERVER_Error object on failure, return nullptr on success.\n The returned error object is owned by 'inference_response' and so\n should not be deleted by the caller.\n\n \\param inference_response The response object.\n \\return a TRITONSERVER_Error indicating the success or failure\n status of the response."]
    pub fn TRITONSERVER_InferenceResponseError(
        inference_response: *mut TRITONSERVER_InferenceResponse,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get model used to produce a response. The caller does not own the\n returned model name value and must not modify or delete it. The\n lifetime of all returned values extends until 'inference_response'\n is deleted.\n\n \\param inference_response The response object.\n \\param model_name Returns the name of the model.\n \\param model_version Returns the version of the model.\n this response.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceResponseModel(
        inference_response: *mut TRITONSERVER_InferenceResponse,
        model_name: *mut *const ::std::os::raw::c_char,
        model_version: *mut i64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the ID of the request corresponding to a response. The caller\n does not own the returned ID and must not modify or delete it. The\n lifetime of all returned values extends until 'inference_response'\n is deleted.\n\n \\param inference_response The response object.\n \\param request_id Returns the ID of the request corresponding to\n this response.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceResponseId(
        inference_response: *mut TRITONSERVER_InferenceResponse,
        request_id: *mut *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the number of parameters available in the response.\n\n \\param inference_response The response object.\n \\param count Returns the number of parameters.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceResponseParameterCount(
        inference_response: *mut TRITONSERVER_InferenceResponse,
        count: *mut u32,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get all information about a parameter. The caller does not own any\n of the returned values and must not modify or delete them. The\n lifetime of all returned values extends until 'inference_response'\n is deleted.\n\n The 'vvalue' returns a void* pointer that must be cast\n appropriately based on 'type'. For example:\n\n   void* vvalue;\n   TRITONSERVER_ParameterType type;\n   TRITONSERVER_InferenceResponseParameter(\n                     response, index, &name, &type, &vvalue);\n   switch (type) {\n     case TRITONSERVER_PARAMETER_BOOL:\n       bool value = *(reinterpret_cast<bool*>(vvalue));\n       ...\n     case TRITONSERVER_PARAMETER_INT:\n       int64_t value = *(reinterpret_cast<int64_t*>(vvalue));\n       ...\n     case TRITONSERVER_PARAMETER_STRING:\n       const char* value = reinterpret_cast<const char*>(vvalue);\n       ...\n\n \\param inference_response The response object.\n \\param index The index of the parameter, must be 0 <= index <\n count, where 'count' is the value returned by\n TRITONSERVER_InferenceResponseParameterCount.\n \\param name Returns the name of the parameter.\n \\param type Returns the type of the parameter.\n \\param vvalue Returns a pointer to the parameter value.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceResponseParameter(
        inference_response: *mut TRITONSERVER_InferenceResponse,
        index: u32,
        name: *mut *const ::std::os::raw::c_char,
        type_: *mut TRITONSERVER_ParameterType,
        vvalue: *mut *const ::std::os::raw::c_void,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the number of outputs available in the response.\n\n \\param inference_response The response object.\n \\param count Returns the number of output tensors.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceResponseOutputCount(
        inference_response: *mut TRITONSERVER_InferenceResponse,
        count: *mut u32,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get all information about an output tensor.  The tensor data is\n returned as the base pointer to the data and the size, in bytes,\n of the data. The caller does not own any of the returned values\n and must not modify or delete them. The lifetime of all returned\n values extends until 'inference_response' is deleted.\n\n \\param inference_response The response object.\n \\param index The index of the output tensor, must be 0 <= index <\n count, where 'count' is the value returned by\n TRITONSERVER_InferenceResponseOutputCount.\n \\param name Returns the name of the output.\n \\param datatype Returns the type of the output.\n \\param shape Returns the shape of the output.\n \\param dim_count Returns the number of dimensions of the returned\n shape.\n \\param base Returns the tensor data for the output.\n \\param byte_size Returns the size, in bytes, of the data.\n \\param memory_type Returns the memory type of the data.\n \\param memory_type_id Returns the memory type id of the data.\n \\param userp The user-specified value associated with the buffer\n in TRITONSERVER_ResponseAllocatorAllocFn_t.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceResponseOutput(
        inference_response: *mut TRITONSERVER_InferenceResponse,
        index: u32,
        name: *mut *const ::std::os::raw::c_char,
        datatype: *mut TRITONSERVER_DataType,
        shape: *mut *const i64,
        dim_count: *mut u64,
        base: *mut *const ::std::os::raw::c_void,
        byte_size: *mut usize,
        memory_type: *mut TRITONSERVER_MemoryType,
        memory_type_id: *mut i64,
        userp: *mut *mut ::std::os::raw::c_void,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get a classification label associated with an output for a given\n index.  The caller does not own the returned label and must not\n modify or delete it. The lifetime of all returned label extends\n until 'inference_response' is deleted.\n\n \\param inference_response The response object.\n \\param index The index of the output tensor, must be 0 <= index <\n count, where 'count' is the value returned by\n TRITONSERVER_InferenceResponseOutputCount.\n \\param class_index The index of the class.\n \\param name Returns the label corresponding to 'class_index' or\n nullptr if no label.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_InferenceResponseOutputClassificationLabel(
        inference_response: *mut TRITONSERVER_InferenceResponse,
        index: u32,
        class_index: usize,
        label: *mut *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Create a new buffer attributes object. The caller takes ownership of\n the TRITONSERVER_BufferAttributes object and must call\n TRITONSERVER_BufferAttributesDelete to release the object.\n\n \\param buffer_attributes Returns the new buffer attributes object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_BufferAttributesNew(
        buffer_attributes: *mut *mut TRITONSERVER_BufferAttributes,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Delete a buffer attributes object.\n\n \\param buffer_attributes The buffer_attributes object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_BufferAttributesDelete(
        buffer_attributes: *mut TRITONSERVER_BufferAttributes,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the memory type id field of the buffer attributes.\n\n \\param buffer_attributes The buffer attributes object.\n \\param memory_type_id Memory type id to assign to the buffer attributes\n object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_BufferAttributesSetMemoryTypeId(
        buffer_attributes: *mut TRITONSERVER_BufferAttributes,
        memory_type_id: i64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the memory type field of the buffer attributes.\n\n \\param buffer_attributes The buffer attributes object.\n \\param memory_type Memory type to assign to the buffer attributes object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_BufferAttributesSetMemoryType(
        buffer_attributes: *mut TRITONSERVER_BufferAttributes,
        memory_type: TRITONSERVER_MemoryType,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the CudaIpcHandle field of the buffer attributes.\n\n \\param buffer_attributes The buffer attributes object.\n \\param cuda_ipc_handle The CudaIpcHandle to assign to the buffer attributes\n object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_BufferAttributesSetCudaIpcHandle(
        buffer_attributes: *mut TRITONSERVER_BufferAttributes,
        cuda_ipc_handle: *mut ::std::os::raw::c_void,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the byte size field of the buffer attributes.\n\n \\param buffer_attributes The buffer attributes object.\n \\param byte_size Byte size to assign to the buffer attributes object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_BufferAttributesSetByteSize(
        buffer_attributes: *mut TRITONSERVER_BufferAttributes,
        byte_size: usize,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the memory type id field of the buffer attributes.\n\n \\param buffer_attributes The buffer attributes object.\n \\param memory_type_id Returns the memory type id associated with the buffer\n attributes object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_BufferAttributesMemoryTypeId(
        buffer_attributes: *mut TRITONSERVER_BufferAttributes,
        memory_type_id: *mut i64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the memory type field of the buffer attributes.\n\n \\param buffer_attributes The buffer attributes object.\n \\param memory_type Returns the memory type associated with the buffer\n attributes object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_BufferAttributesMemoryType(
        buffer_attributes: *mut TRITONSERVER_BufferAttributes,
        memory_type: *mut TRITONSERVER_MemoryType,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the CudaIpcHandle field of the buffer attributes object.\n\n \\param buffer_attributes The buffer attributes object.\n \\param cuda_ipc_handle Returns the memory type associated with the buffer\n attributes object. If the cudaIpcHandle does not exist for the buffer,\n nullptr will be returned.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_BufferAttributesCudaIpcHandle(
        buffer_attributes: *mut TRITONSERVER_BufferAttributes,
        cuda_ipc_handle: *mut *mut ::std::os::raw::c_void,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the byte size field of the buffer attributes.\n\n \\param buffer_attributes The buffer attributes object.\n \\param byte_size Returns the byte size associated with the buffer attributes\n object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_BufferAttributesByteSize(
        buffer_attributes: *mut TRITONSERVER_BufferAttributes,
        byte_size: *mut usize,
    ) -> *mut TRITONSERVER_Error;
}
pub const tritonserver_modelcontrolmode_enum_TRITONSERVER_MODEL_CONTROL_NONE:
    tritonserver_modelcontrolmode_enum = 0;
pub const tritonserver_modelcontrolmode_enum_TRITONSERVER_MODEL_CONTROL_POLL:
    tritonserver_modelcontrolmode_enum = 1;
pub const tritonserver_modelcontrolmode_enum_TRITONSERVER_MODEL_CONTROL_EXPLICIT:
    tritonserver_modelcontrolmode_enum = 2;
#[doc = " Model control modes"]
pub type tritonserver_modelcontrolmode_enum = ::std::os::raw::c_uint;
#[doc = " Model control modes"]
pub use self::tritonserver_modelcontrolmode_enum as TRITONSERVER_ModelControlMode;
pub const tritonserver_ratelimitmode_enum_TRITONSERVER_RATE_LIMIT_OFF:
    tritonserver_ratelimitmode_enum = 0;
pub const tritonserver_ratelimitmode_enum_TRITONSERVER_RATE_LIMIT_EXEC_COUNT:
    tritonserver_ratelimitmode_enum = 1;
#[doc = " Rate limit modes"]
pub type tritonserver_ratelimitmode_enum = ::std::os::raw::c_uint;
#[doc = " Rate limit modes"]
pub use self::tritonserver_ratelimitmode_enum as TRITONSERVER_RateLimitMode;
extern "C" {
    #[doc = " Create a new server options object. The caller takes ownership of\n the TRITONSERVER_ServerOptions object and must call\n TRITONSERVER_ServerOptionsDelete to release the object.\n\n \\param options Returns the new server options object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsNew(
        options: *mut *mut TRITONSERVER_ServerOptions,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Delete a server options object.\n\n \\param options The server options object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsDelete(
        options: *mut TRITONSERVER_ServerOptions,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the textual ID for the server in a server options. The ID is a\n name that identifies the server.\n\n \\param options The server options object.\n \\param server_id The server identifier.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetServerId(
        options: *mut TRITONSERVER_ServerOptions,
        server_id: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the model repository path in a server options. The path must be\n the full absolute path to the model repository. This function can be called\n multiple times with different paths to set multiple model repositories.\n Note that if a model is not unique across all model repositories\n at any time, the model will not be available.\n\n \\param options The server options object.\n \\param model_repository_path The full path to the model repository.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetModelRepositoryPath(
        options: *mut TRITONSERVER_ServerOptions,
        model_repository_path: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the model control mode in a server options. For each mode the models\n will be managed as the following:\n\n   TRITONSERVER_MODEL_CONTROL_NONE: the models in model repository will be\n   loaded on startup. After startup any changes to the model repository will\n   be ignored. Calling TRITONSERVER_ServerPollModelRepository will result in\n   an error.\n\n   TRITONSERVER_MODEL_CONTROL_POLL: the models in model repository will be\n   loaded on startup. The model repository can be polled periodically using\n   TRITONSERVER_ServerPollModelRepository and the server will load, unload,\n   and updated models according to changes in the model repository.\n\n   TRITONSERVER_MODEL_CONTROL_EXPLICIT: the models in model repository will\n   not be loaded on startup. The corresponding model control APIs must be\n   called to load / unload a model in the model repository.\n\n \\param options The server options object.\n \\param mode The mode to use for the model control.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetModelControlMode(
        options: *mut TRITONSERVER_ServerOptions,
        mode: TRITONSERVER_ModelControlMode,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the model to be loaded at startup in a server options. The model must be\n present in one, and only one, of the specified model repositories.\n This function can be called multiple times with different model name\n to set multiple startup models.\n Note that it only takes affect on TRITONSERVER_MODEL_CONTROL_EXPLICIT mode.\n\n \\param options The server options object.\n \\param mode_name The name of the model to load on startup.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetStartupModel(
        options: *mut TRITONSERVER_ServerOptions,
        model_name: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Enable or disable strict model configuration handling in a server\n options.\n\n \\param options The server options object.\n \\param strict True to enable strict model configuration handling,\n false to disable.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetStrictModelConfig(
        options: *mut TRITONSERVER_ServerOptions,
        strict: bool,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the rate limit mode in a server options.\n\n   TRITONSERVER_RATE_LIMIT_EXEC_COUNT: The rate limiting prioritizes the\n   inference execution using the number of times each instance has got a\n   chance to run. The execution gets to run only when its resource\n   constraints are satisfied.\n\n   TRITONSERVER_RATE_LIMIT_OFF: The rate limiting is turned off and the\n   inference gets executed whenever an instance is available.\n\n \\param options The server options object.\n \\param mode The mode to use for the rate limiting. By default, execution\n count is used to determine the priorities.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetRateLimiterMode(
        options: *mut TRITONSERVER_ServerOptions,
        mode: TRITONSERVER_RateLimitMode,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Add resource count for rate limiting.\n\n \\param options The server options object.\n \\param name The name of the resource.\n \\param count The count of the resource.\n \\param device The device identifier for the resource. A value of -1\n indicates that the specified number of resources are available on every\n device. The device value is ignored for a global resource. The server\n will use the rate limiter configuration specified for instance groups\n in model config to determine whether resource is global. In case of\n conflicting resource type in different model configurations, server\n will raise an appropriate error while loading model.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsAddRateLimiterResource(
        options: *mut TRITONSERVER_ServerOptions,
        resource_name: *const ::std::os::raw::c_char,
        resource_count: usize,
        device: ::std::os::raw::c_int,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the total pinned memory byte size that the server can allocate\n in a server options. The pinned memory pool will be shared across\n Triton itself and the backends that use\n TRITONBACKEND_MemoryManager to allocate memory.\n\n \\param options The server options object.\n \\param size The pinned memory pool byte size.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetPinnedMemoryPoolByteSize(
        options: *mut TRITONSERVER_ServerOptions,
        size: u64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the total CUDA memory byte size that the server can allocate\n on given GPU device in a server options. The pinned memory pool\n will be shared across Triton itself and the backends that use\n TRITONBACKEND_MemoryManager to allocate memory.\n\n \\param options The server options object.\n \\param gpu_device The GPU device to allocate the memory pool.\n \\param size The CUDA memory pool byte size.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetCudaMemoryPoolByteSize(
        options: *mut TRITONSERVER_ServerOptions,
        gpu_device: ::std::os::raw::c_int,
        size: u64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the total response cache byte size that the server can allocate in CPU\n memory. The response cache will be shared across all inference requests and\n across all models.\n\n \\param options The server options object.\n \\param size The total response cache byte size.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetResponseCacheByteSize(
        options: *mut TRITONSERVER_ServerOptions,
        size: u64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the minimum support CUDA compute capability in a server\n options.\n\n \\param options The server options object.\n \\param cc The minimum CUDA compute capability.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetMinSupportedComputeCapability(
        options: *mut TRITONSERVER_ServerOptions,
        cc: f64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Enable or disable exit-on-error in a server options.\n\n \\param options The server options object.\n \\param exit True to enable exiting on intialization error, false\n to continue.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetExitOnError(
        options: *mut TRITONSERVER_ServerOptions,
        exit: bool,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Enable or disable strict readiness handling in a server options.\n\n \\param options The server options object.\n \\param strict True to enable strict readiness handling, false to\n disable.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetStrictReadiness(
        options: *mut TRITONSERVER_ServerOptions,
        strict: bool,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the exit timeout, in seconds, for the server in a server\n options.\n\n \\param options The server options object.\n \\param timeout The exit timeout, in seconds.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetExitTimeout(
        options: *mut TRITONSERVER_ServerOptions,
        timeout: ::std::os::raw::c_uint,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the number of threads used in buffer manager in a server options.\n\n \\param options The server options object.\n \\param thread_count The number of threads.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetBufferManagerThreadCount(
        options: *mut TRITONSERVER_ServerOptions,
        thread_count: ::std::os::raw::c_uint,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the number of threads to concurrently load models in a server options.\n\n \\param options The server options object.\n \\param thread_count The number of threads.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetModelLoadThreadCount(
        options: *mut TRITONSERVER_ServerOptions,
        thread_count: ::std::os::raw::c_uint,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Provide a log output file.\n\n \\param options The server options object.\n \\param file a string defining the file where the log outputs will be saved.\n An empty string for the file name will cause triton to direct logging\n facilities to the console\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetLogFile(
        options: *mut TRITONSERVER_ServerOptions,
        file: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Enable or disable info level logging.\n\n \\param options The server options object.\n \\param log True to enable info logging, false to disable.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetLogInfo(
        options: *mut TRITONSERVER_ServerOptions,
        log: bool,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Enable or disable warning level logging.\n\n \\param options The server options object.\n \\param log True to enable warning logging, false to disable.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetLogWarn(
        options: *mut TRITONSERVER_ServerOptions,
        log: bool,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Enable or disable error level logging.\n\n \\param options The server options object.\n \\param log True to enable error logging, false to disable.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetLogError(
        options: *mut TRITONSERVER_ServerOptions,
        log: bool,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the logging format.\n\n \\param options The server options object.\n \\param format The logging format.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetLogFormat(
        options: *mut TRITONSERVER_ServerOptions,
        format: TRITONSERVER_LogFormat,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set verbose logging level. Level zero disables verbose logging.\n\n \\param options The server options object.\n \\param level The verbose logging level.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetLogVerbose(
        options: *mut TRITONSERVER_ServerOptions,
        level: ::std::os::raw::c_int,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Enable or disable metrics collection in a server options.\n\n \\param options The server options object.\n \\param metrics True to enable metrics, false to disable.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetMetrics(
        options: *mut TRITONSERVER_ServerOptions,
        metrics: bool,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Enable or disable GPU metrics collection in a server options. GPU\n metrics are collected if both this option and\n TRITONSERVER_ServerOptionsSetMetrics are true.\n\n \\param options The server options object.\n \\param gpu_metrics True to enable GPU metrics, false to disable.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetGpuMetrics(
        options: *mut TRITONSERVER_ServerOptions,
        gpu_metrics: bool,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Enable or disable CPU metrics collection in a server options. CPU\n metrics are collected if both this option and\n TRITONSERVER_ServerOptionsSetMetrics are true.\n\n \\param options The server options object.\n \\param cpu_metrics True to enable CPU metrics, false to disable.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetCpuMetrics(
        options: *mut TRITONSERVER_ServerOptions,
        cpu_metrics: bool,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the interval for metrics collection in a server options.\n This is 2000 milliseconds by default.\n\n \\param options The server options object.\n \\param metrics_interval_ms The time interval in ms between\n successive metrics updates.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetMetricsInterval(
        options: *mut TRITONSERVER_ServerOptions,
        metrics_interval_ms: u64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the directory containing backend shared libraries. This\n directory is searched last after the version and model directory\n in the model repository when looking for the backend shared\n library for a model. If the backend is named 'be' the directory\n searched is 'backend_dir'/be/libtriton_be.so.\n\n \\param options The server options object.\n \\param backend_dir The full path of the backend directory.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetBackendDirectory(
        options: *mut TRITONSERVER_ServerOptions,
        backend_dir: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the directory containing repository agent shared libraries. This\n directory is searched when looking for the repository agent shared\n library for a model. If the backend is named 'ra' the directory\n searched is 'repoagent_dir'/ra/libtritonrepoagent_ra.so.\n\n \\param options The server options object.\n \\param repoagent_dir The full path of the repository agent directory.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetRepoAgentDirectory(
        options: *mut TRITONSERVER_ServerOptions,
        repoagent_dir: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Specify the limit on memory usage as a fraction on the device identified by\n 'kind' and 'device_id'. If model loading on the device is requested and the\n current memory usage exceeds the limit, the load will be rejected. If not\n specified, the limit will not be set.\n\n Currently support TRITONSERVER_INSTANCEGROUPKIND_GPU\n\n \\param options The server options object.\n \\param kind The kind of the device.\n \\param device_id The id of the device.\n \\param fraction The limit on memory usage as a fraction\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetModelLoadDeviceLimit(
        options: *mut TRITONSERVER_ServerOptions,
        kind: TRITONSERVER_InstanceGroupKind,
        device_id: ::std::os::raw::c_int,
        fraction: f64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set a configuration setting for a named backend in a server\n options.\n\n \\param options The server options object.\n \\param backend_name The name of the backend.\n \\param setting The name of the setting.\n \\param value The setting value.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetBackendConfig(
        options: *mut TRITONSERVER_ServerOptions,
        backend_name: *const ::std::os::raw::c_char,
        setting: *const ::std::os::raw::c_char,
        value: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set a host policy setting for a given policy name in a server options.\n\n \\param options The server options object.\n \\param policy_name The name of the policy.\n \\param setting The name of the setting.\n \\param value The setting value.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerOptionsSetHostPolicy(
        options: *mut TRITONSERVER_ServerOptions,
        policy_name: *const ::std::os::raw::c_char,
        setting: *const ::std::os::raw::c_char,
        value: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
pub const tritonserver_batchflag_enum_TRITONSERVER_BATCH_UNKNOWN: tritonserver_batchflag_enum = 1;
pub const tritonserver_batchflag_enum_TRITONSERVER_BATCH_FIRST_DIM: tritonserver_batchflag_enum = 2;
#[doc = " Model batch flags. The enum values must be power-of-2 values."]
pub type tritonserver_batchflag_enum = ::std::os::raw::c_uint;
#[doc = " Model batch flags. The enum values must be power-of-2 values."]
pub use self::tritonserver_batchflag_enum as TRITONSERVER_ModelBatchFlag;
pub const tritonserver_modelindexflag_enum_TRITONSERVER_INDEX_FLAG_READY:
    tritonserver_modelindexflag_enum = 1;
#[doc = " Model index flags. The enum values must be power-of-2 values."]
pub type tritonserver_modelindexflag_enum = ::std::os::raw::c_uint;
#[doc = " Model index flags. The enum values must be power-of-2 values."]
pub use self::tritonserver_modelindexflag_enum as TRITONSERVER_ModelIndexFlag;
pub const tritonserver_txn_property_flag_enum_TRITONSERVER_TXN_ONE_TO_ONE:
    tritonserver_txn_property_flag_enum = 1;
pub const tritonserver_txn_property_flag_enum_TRITONSERVER_TXN_DECOUPLED:
    tritonserver_txn_property_flag_enum = 2;
#[doc = " Model transaction policy flags. The enum values must be\n power-of-2 values."]
pub type tritonserver_txn_property_flag_enum = ::std::os::raw::c_uint;
#[doc = " Model transaction policy flags. The enum values must be\n power-of-2 values."]
pub use self::tritonserver_txn_property_flag_enum as TRITONSERVER_ModelTxnPropertyFlag;
extern "C" {
    #[doc = " Create a new server object. The caller takes ownership of the\n TRITONSERVER_Server object and must call TRITONSERVER_ServerDelete\n to release the object.\n\n \\param server Returns the new inference server object.\n \\param options The inference server options object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerNew(
        server: *mut *mut TRITONSERVER_Server,
        options: *mut TRITONSERVER_ServerOptions,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Delete a server object. If server is not already stopped it is\n stopped before being deleted.\n\n \\param server The inference server object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerDelete(server: *mut TRITONSERVER_Server) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Stop a server object. A server can't be restarted once it is\n stopped.\n\n \\param server The inference server object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerStop(server: *mut TRITONSERVER_Server) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Register a new model repository. Not available in polling mode.\n\n \\param server The inference server object.\n \\param repository_path The full path to the model repository.\n \\param name_mapping List of name_mapping parameters. Each mapping has\n the model directory name as its key, overriden model name as its value.\n \\param model_count Number of mappings provided.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerRegisterModelRepository(
        server: *mut TRITONSERVER_Server,
        repository_path: *const ::std::os::raw::c_char,
        name_mapping: *mut *const TRITONSERVER_Parameter,
        mapping_count: u32,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Unregister a model repository. Not available in polling mode.\n\n \\param server The inference server object.\n \\param repository_path The full path to the model repository.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerUnregisterModelRepository(
        server: *mut TRITONSERVER_Server,
        repository_path: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Check the model repository for changes and update server state\n based on those changes.\n\n \\param server The inference server object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerPollModelRepository(
        server: *mut TRITONSERVER_Server,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Is the server live?\n\n \\param server The inference server object.\n \\param live Returns true if server is live, false otherwise.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerIsLive(
        server: *mut TRITONSERVER_Server,
        live: *mut bool,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Is the server ready?\n\n \\param server The inference server object.\n \\param ready Returns true if server is ready, false otherwise.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerIsReady(
        server: *mut TRITONSERVER_Server,
        ready: *mut bool,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Is the model ready?\n\n \\param server The inference server object.\n \\param model_name The name of the model to get readiness for.\n \\param model_version The version of the model to get readiness\n for.  If -1 then the server will choose a version based on the\n model's policy.\n \\param ready Returns true if server is ready, false otherwise.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerModelIsReady(
        server: *mut TRITONSERVER_Server,
        model_name: *const ::std::os::raw::c_char,
        model_version: i64,
        ready: *mut bool,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the batch properties of the model. The properties are\n communicated by a flags value and an (optional) object returned by\n 'voidp'.\n\n   - TRITONSERVER_BATCH_UNKNOWN: Triton cannot determine the\n     batching properties of the model. This means that the model\n     does not support batching in any way that is useable by\n     Triton. The returned 'voidp' value is nullptr.\n\n   - TRITONSERVER_BATCH_FIRST_DIM: The model supports batching\n     along the first dimension of every input and output\n     tensor. Triton schedulers that perform batching can\n     automatically batch inference requests along this dimension.\n     The returned 'voidp' value is nullptr.\n\n \\param server The inference server object.\n \\param model_name The name of the model.\n \\param model_version The version of the model.  If -1 then the\n server will choose a version based on the model's policy.\n \\param flags Returns flags indicating the batch properties of the\n model.\n \\param voidp If non-nullptr, returns a point specific to the\n 'flags' value.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerModelBatchProperties(
        server: *mut TRITONSERVER_Server,
        model_name: *const ::std::os::raw::c_char,
        model_version: i64,
        flags: *mut u32,
        voidp: *mut *mut ::std::os::raw::c_void,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the transaction policy of the model. The policy is\n communicated by a flags value.\n\n   - TRITONSERVER_TXN_ONE_TO_ONE: The model generates exactly\n     one response per request.\n\n   - TRITONSERVER_TXN_DECOUPLED: The model may generate zero\n     to many responses per request.\n\n \\param server The inference server object.\n \\param model_name The name of the model.\n \\param model_version The version of the model.  If -1 then the\n server will choose a version based on the model's policy.\n \\param txn_flags Returns flags indicating the transaction policy of the\n model.\n \\param voidp If non-nullptr, returns a point specific to the 'flags' value.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerModelTransactionProperties(
        server: *mut TRITONSERVER_Server,
        model_name: *const ::std::os::raw::c_char,
        model_version: i64,
        txn_flags: *mut u32,
        voidp: *mut *mut ::std::os::raw::c_void,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the metadata of the server as a TRITONSERVER_Message object.\n The caller takes ownership of the message object and must call\n TRITONSERVER_MessageDelete to release the object.\n\n \\param server The inference server object.\n \\param server_metadata Returns the server metadata message.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerMetadata(
        server: *mut TRITONSERVER_Server,
        server_metadata: *mut *mut TRITONSERVER_Message,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the metadata of a model as a TRITONSERVER_Message\n object.  The caller takes ownership of the message object and must\n call TRITONSERVER_MessageDelete to release the object.\n\n \\param server The inference server object.\n \\param model_name The name of the model.\n \\param model_version The version of the model.\n If -1 then the server will choose a version based on the model's\n policy.\n \\param model_metadata Returns the model metadata message.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerModelMetadata(
        server: *mut TRITONSERVER_Server,
        model_name: *const ::std::os::raw::c_char,
        model_version: i64,
        model_metadata: *mut *mut TRITONSERVER_Message,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the statistics of a model as a TRITONSERVER_Message\n object. The caller takes ownership of the object and must call\n TRITONSERVER_MessageDelete to release the object.\n\n \\param server The inference server object.\n \\param model_name The name of the model.\n If empty, then statistics for all available models will be returned,\n and the server will choose a version based on those models' policies.\n \\param model_version The version of the model.  If -1 then the\n server will choose a version based on the model's policy.\n \\param model_stats Returns the model statistics message.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerModelStatistics(
        server: *mut TRITONSERVER_Server,
        model_name: *const ::std::os::raw::c_char,
        model_version: i64,
        model_stats: *mut *mut TRITONSERVER_Message,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the configuration of a model as a TRITONSERVER_Message object.\n The caller takes ownership of the message object and must call\n TRITONSERVER_MessageDelete to release the object.\n\n \\param server The inference server object.\n \\param model_name The name of the model.\n \\param model_version The version of the model.  If -1 then the\n server will choose a version based on the model's policy.\n \\param config_version The model configuration will be returned in\n a format matching this version. If the configuration cannot be\n represented in the requested version's format then an error will\n be returned. Currently only version 1 is supported.\n \\param model_config Returns the model config message.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerModelConfig(
        server: *mut TRITONSERVER_Server,
        model_name: *const ::std::os::raw::c_char,
        model_version: i64,
        config_version: u32,
        model_config: *mut *mut TRITONSERVER_Message,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the index of all unique models in the model repositories as a\n TRITONSERVER_Message object. The caller takes ownership of the\n message object and must call TRITONSERVER_MessageDelete to release\n the object.\n\n If TRITONSERVER_INDEX_FLAG_READY is set in 'flags' only the models\n that are loaded into the server and ready for inferencing are\n returned.\n\n \\param server The inference server object.\n \\param flags TRITONSERVER_ModelIndexFlag flags that control how to\n collect the index.\n \\param model_index Return the model index message that holds the\n index of all models contained in the server's model repository(s).\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerModelIndex(
        server: *mut TRITONSERVER_Server,
        flags: u32,
        model_index: *mut *mut TRITONSERVER_Message,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Load the requested model or reload the model if it is already\n loaded. The function does not return until the model is loaded or\n fails to load. Returned error indicates if model loaded\n successfully or not.\n\n \\param server The inference server object.\n \\param model_name The name of the model.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerLoadModel(
        server: *mut TRITONSERVER_Server,
        model_name: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Load the requested model or reload the model if it is already\n loaded, with load parameters provided. The function does not return until\n the model is loaded or fails to load. Returned error indicates if model\n loaded successfully or not.\n Currently the below parameter names are recognized:\n - \"config\" : string parameter that contains a JSON representation of the\n model configuration. This config will be used for loading the model instead\n of the one in the model directory.\n\n \\param server The inference server object.\n \\param model_name The name of the model.\n \\param parameters The array of load parameters.\n \\param parameter_count The number of parameters.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerLoadModelWithParameters(
        server: *mut TRITONSERVER_Server,
        model_name: *const ::std::os::raw::c_char,
        parameters: *mut *const TRITONSERVER_Parameter,
        parameter_count: u64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Unload the requested model. Unloading a model that is not loaded\n on server has no affect and success code will be returned.\n The function does not wait for the requested model to be fully unload\n and success code will be returned.\n Returned error indicates if model unloaded successfully or not.\n\n \\param server The inference server object.\n \\param model_name The name of the model.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerUnloadModel(
        server: *mut TRITONSERVER_Server,
        model_name: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Unload the requested model, and also unload any dependent model that\n was loaded along with the requested model (for example, the models composing\n an ensemble). Unloading a model that is not loaded\n on server has no affect and success code will be returned.\n The function does not wait for the requested model and all dependent\n models to be fully unload and success code will be returned.\n Returned error indicates if model unloaded successfully or not.\n\n \\param server The inference server object.\n \\param model_name The name of the model.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerUnloadModelAndDependents(
        server: *mut TRITONSERVER_Server,
        model_name: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the current metrics for the server. The caller takes ownership\n of the metrics object and must call TRITONSERVER_MetricsDelete to\n release the object.\n\n \\param server The inference server object.\n \\param metrics Returns the metrics.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerMetrics(
        server: *mut TRITONSERVER_Server,
        metrics: *mut *mut TRITONSERVER_Metrics,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Perform inference using the meta-data and inputs supplied by the\n 'inference_request'. If the function returns success, then the\n caller releases ownership of 'inference_request' and must not\n access it in any way after this call, until ownership is returned\n via the 'request_release_fn' callback registered in the request\n object with TRITONSERVER_InferenceRequestSetReleaseCallback.\n\n The function unconditionally takes ownership of 'trace' and so the\n caller must not access it in any way after this call (except in\n the trace activity callbacks) until ownership is returned via the\n trace's release_fn callback.\n\n Responses produced for this request are returned using the\n allocator and callback registered with the request by\n TRITONSERVER_InferenceRequestSetResponseCallback.\n\n \\param server The inference server object.\n \\param inference_request The request object.\n \\param trace The trace object for this request, or nullptr if no\n tracing.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_ServerInferAsync(
        server: *mut TRITONSERVER_Server,
        inference_request: *mut TRITONSERVER_InferenceRequest,
        trace: *mut TRITONSERVER_InferenceTrace,
    ) -> *mut TRITONSERVER_Error;
}
pub const TRITONSERVER_metrickind_enum_TRITONSERVER_METRIC_KIND_COUNTER:
    TRITONSERVER_metrickind_enum = 0;
pub const TRITONSERVER_metrickind_enum_TRITONSERVER_METRIC_KIND_GAUGE:
    TRITONSERVER_metrickind_enum = 1;
#[doc = " TRITONSERVER_MetricKind\n\n Types of metrics recognized by TRITONSERVER.\n"]
pub type TRITONSERVER_metrickind_enum = ::std::os::raw::c_uint;
#[doc = " TRITONSERVER_MetricKind\n\n Types of metrics recognized by TRITONSERVER.\n"]
pub use self::TRITONSERVER_metrickind_enum as TRITONSERVER_MetricKind;
extern "C" {
    #[doc = " Create a new metric family object. The caller takes ownership of the\n TRITONSERVER_MetricFamily object and must call\n TRITONSERVER_MetricFamilyDelete to release the object.\n\n \\param family Returns the new metric family object.\n \\param kind The type of metric family to create.\n \\param name The name of the metric family seen when calling the metrics\n endpoint.\n \\param description The description of the metric family seen when\n calling the metrics endpoint.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_MetricFamilyNew(
        family: *mut *mut TRITONSERVER_MetricFamily,
        kind: TRITONSERVER_MetricKind,
        name: *const ::std::os::raw::c_char,
        description: *const ::std::os::raw::c_char,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Delete a metric family object.\n A struct TRITONSERVER_MetricFamily* object should be deleted AFTER its\n corresponding struct TRITONSERVER_Metric* objects have been deleted.\n Attempting to delete a family before its metrics will return an error.\n\n \\param family The metric family object to delete.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_MetricFamilyDelete(
        family: *mut TRITONSERVER_MetricFamily,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Create a new metric object. The caller takes ownership of the\n TRITONSERVER_Metric object and must call\n TRITONSERVER_MetricDelete to release the object. The caller is also\n responsible for ownership of the labels passed in. Each label can be deleted\n immediately after creating the metric with TRITONSERVER_ParameterDelete\n if not re-using the labels.\n\n \\param metric Returns the new metric object.\n \\param family The metric family to add this new metric to.\n \\param labels The array of labels to associate with this new metric.\n \\param label_count The number of labels.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_MetricNew(
        metric: *mut *mut TRITONSERVER_Metric,
        family: *mut TRITONSERVER_MetricFamily,
        labels: *mut *const TRITONSERVER_Parameter,
        label_count: u64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Delete a metric object.\n All struct TRITONSERVER_Metric* objects should be deleted BEFORE their\n corresponding struct TRITONSERVER_MetricFamily* objects have been deleted.\n If a family is deleted before its metrics, an error will be returned.\n\n \\param metric The metric object to delete.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_MetricDelete(metric: *mut TRITONSERVER_Metric) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the current value of a metric object.\n Supports metrics of kind TRITONSERVER_METRIC_KIND_COUNTER\n and TRITONSERVER_METRIC_KIND_GAUGE, and returns\n TRITONSERVER_ERROR_UNSUPPORTED for unsupported TRITONSERVER_MetricKind.\n\n \\param metric The metric object to query.\n \\param value Returns the current value of the metric object.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_MetricValue(
        metric: *mut TRITONSERVER_Metric,
        value: *mut f64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Increment the current value of metric by value.\n Supports metrics of kind TRITONSERVER_METRIC_KIND_GAUGE for any value,\n and TRITONSERVER_METRIC_KIND_COUNTER for non-negative values. Returns\n TRITONSERVER_ERROR_UNSUPPORTED for unsupported TRITONSERVER_MetricKind\n and TRITONSERVER_ERROR_INVALID_ARG for negative values on a\n TRITONSERVER_METRIC_KIND_COUNTER metric.\n\n \\param metric The metric object to update.\n \\param value The amount to increment the metric's value by.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_MetricIncrement(
        metric: *mut TRITONSERVER_Metric,
        value: f64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Set the current value of metric to value.\n Supports metrics of kind TRITONSERVER_METRIC_KIND_GAUGE and returns\n TRITONSERVER_ERROR_UNSUPPORTED for unsupported TRITONSERVER_MetricKind.\n\n \\param metric The metric object to update.\n \\param value The amount to set metric's value to.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_MetricSet(
        metric: *mut TRITONSERVER_Metric,
        value: f64,
    ) -> *mut TRITONSERVER_Error;
}
extern "C" {
    #[doc = " Get the TRITONSERVER_MetricKind of metric and its corresponding family.\n\n \\param metric The metric object to query.\n \\param kind Returns the TRITONSERVER_MetricKind of metric.\n \\return a TRITONSERVER_Error indicating success or failure."]
    pub fn TRITONSERVER_GetMetricKind(
        metric: *mut TRITONSERVER_Metric,
        kind: *mut TRITONSERVER_MetricKind,
    ) -> *mut TRITONSERVER_Error;
}
